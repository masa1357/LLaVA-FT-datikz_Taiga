{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e967348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421ea8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be05292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.gradepred_data import GradePredictionDataset, collate_fn\n",
    "from src.gradeexplanation_data import GradeExplanationDataset, GradeExplanationCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81892d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd().parent\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "data = GradeExplanationDataset(dataset_path=DATA_PATH)\n",
    "Q1_data = GradeExplanationDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    question_filter=[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b174f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5081305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史',\n",
       "  'Q2': '情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'フランスの腕木通信は知らなかったのでおもしろいと思いました。'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号',\n",
       "  'Q2': '符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。',\n",
       "  'Q3': '最適符号の定義',\n",
       "  'Q4': '平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。',\n",
       "  'Q5': '前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量',\n",
       "  'Q2': '情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい',\n",
       "  'Q3': '曖昧さ=log の証明',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'エントロピーがまだよくわかっていないので、しっかり復習したいです'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量',\n",
       "  'Q2': '誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、',\n",
       "  'Q3': '通信路符号化定理、検査ビット',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム',\n",
       "  'Q2': 'アルゴリズムの定義について',\n",
       "  'Q3': '根付き木がまだよく分からなかった。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート',\n",
       "  'Q2': 'それぞれのソートのやり方',\n",
       "  'Q3': 'ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索',\n",
       "  'Q2': 'マージソートのやり方、二分探索のアルゴリズム',\n",
       "  'Q3': 'キーワードの二分探索がちょっと微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '線形探索と比べて、二分探索の計算量の少なさに驚きました。'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング',\n",
       "  'Q2': 'データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと',\n",
       "  'Q2': '人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細',\n",
       "  'Q3': 'オープン戦略のあたりがまだ曖昧です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用',\n",
       "  'Q2': '非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用',\n",
       "  'Q3': 'とくにないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権',\n",
       "  'Q2': 'データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方',\n",
       "  'Q3': 'オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用',\n",
       "  'Q2': 'ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用',\n",
       "  'Q3': 'max距離の使い方とコサイン類似度が微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方',\n",
       "  'Q2': '棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点',\n",
       "  'Q3': '多次元データの可視化',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出',\n",
       "  'Q2': '相関係数の求め方、相関や分散や統計的検定の特徴',\n",
       "  'Q3': '微分フィルタ、ソーベルフィルタ',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト',\n",
       "  'Q2': 'ラプラシアンフィルタについて',\n",
       "  'Q3': 'NaN',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 31\n",
    "data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d488c611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_data.__len__()\n",
    "Q1_data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ed454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3c847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_data = GradePredictionDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    question_filter=[1],\n",
    "    concatenate=True,\n",
    "    mode = \"train\",\n",
    ")\n",
    "Q1_data.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4758cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('L01-Q1: '\n",
      " '現代社会は高度情報社会であり、情報通信機器を扱う必要がある一方理科離れが起きている。そんな社会を生きるには情報科学を学ぶ必要がある。高校で学ぶ「情報」はアプリケーションの使い方やしてはいけないことの暗記が主な内容であったが、この講義ではサイエンスとしての情報を学んでいく。 '\n",
      " '情報通信機器は文字、絵や写真、音や声など様々な情報を0と1の並びで扱う。情報源符号化はできるだけ短く表現し、一意に、素早く元に戻せる。通信路符号化は伝送中にエラーを自動検出し、自動訂正する。暗号化は秘密を守りながら通信する。 '\n",
      " '情報を伝えることは大昔から様々な方法で行われてきた。そのなかでも特徴的なのは手旗信号や腕木信号、モールス信号だ。また、1876年にグラハム・ベルによって発明された電話は活気的だった。\\n'\n",
      " 'L02-Q1: '\n",
      " '情報源符号化の際に符号語の置き方を工夫することで符号化の長さをより短くすることができる。具体的には現れやすい記号を短い符号語に、現れにくい記号を長い符号語にする。情報源符号化は一意に戻せること、素早く戻せることが前提であり、これらを満たすものとして語頭符号がある。また、平均符号語長の下限はエントロピーである。\\n'\n",
      " 'L03-Q1: '\n",
      " '曖昧さの減少は得られた情報の量であり、これを求めるとき生起確率をPとするとーlog2Pとなる。情報量の期待値はp1(-log2p1)+。。。。pm(-log2p)となり、エントロピーと一致する。相互情報量について確率変数X、Yの相互情報量をI(X、Y)=H(X)-H(X|Y)で定める。XとYが無関係の場合、I(X、Y)=0。\\n'\n",
      " 'L04-Q1: '\n",
      " '通信路を介してビット列を伝送する際にノイズの影響のよってビットの反転が起きるが、その確率(反転確率)をPとすると0<P<0。5となる。ブロック誤り率はPB=1-(1-p)^k '\n",
      " '(ブロックのサイズをkビットとする)。ノイズの対策として通信路を改善してpを小さくする、符号化を工夫するの二つ。自動誤り検出、訂正はハミング距離(XとYで違う個数)を原理に持つ。符号語どうしがs+1以上離れているときs個の誤りについて自動検出可能。2t+1以上のときt個の誤りについて自動訂正可能。3次繰り返し符号は3ビットにおいてビットの反転が一個以下のとき、誤り訂正可能。n次に置き換えることができ、ブロック誤り率:PB≒(4p(1-p))^n/2、符号化効率:R=1/n(nを大きくするほど伝送速度は低下)。通信路容量はC=1-H(p) '\n",
      " 'ブロック誤り率はR=C-ε 符号化効率PB≦δ\\n'\n",
      " 'L05-Q1: '\n",
      " '科学において物理的アプローチとCS的アプローチがある。コンピュータサイエンスは基礎科学になりうるものであり、独自の理論体系がある。関数の計算方法を示す手続きをアルゴリズムという。コンピュータが分かる言葉でアルゴリズムを記述したものがプログラムである。\\n'\n",
      " 'L06-Q1: '\n",
      " 'アルゴリズムの一つとしてユークリット互除法がある。ソートは並び替えのことで昇順は小さい値から大きい値に、降順は大きい値から小さい値に並び替える。バブルソートは隣り合う要素の大小の比較をしながら整列する。選択ソートは最大の要素を探し、それと最後の要素を入れ替える。時間計算量はもっとも時間のかかる上界を考える。\\n'\n",
      " 'L07-Q1: '\n",
      " 'アルゴリズムのなかには二進木を使ったソートがある。そのソートは通りがけ順に読むが、入力数列の並び方で計算時間が変わる。また、2進木を使ったソートの中で節点数n、高さhの2進木が深さdの節点はちょうど2^d個存在し、深さhの節点は左から順に存在する、どの節点の値も、自分の親の値に格納された値以下であるという二つの条件を満たす木をヒープという。マージソートはすでに整列された2つの入力数列から整列された1つの数列を出力する操作をするソートである。\\n'\n",
      " 'L08-Q1: '\n",
      " '情報探索のなかでも線形探索と二分探索がある。線形探索がしらみつぶし的な手法なのに対して二分探索は探索する範囲は半分づつ減っていくので効率的である。そして二分探索の時間計算量はO(klog)である。データといってもさまざまな種類のデータがあり、量的データのうち比率データ、間隔データ、質的データのうち順位データ、カテゴリーデータがある。データ分析は非常に身近なことであり、小学生でもしている。\\n'\n",
      " 'L09-Q1: '\n",
      " '人工知能とは人間の知能を真似する機械であり、我々にとっても身近なものになっている。人工知能には特化型AIと汎用AIの2種類がある。AIはビジネスにも活用されている。機械学習には教師あり学習と教師なし学習の二つがある。機械学習は多くのデータを蓄積し、それらのデータを利用して関数をいじる。\\n'\n",
      " 'L10-Q1: '\n",
      " '非構造化データ処理の例として言語処理、画像処理、音声処理が挙げられる。言語データは自然言語処理によって分析され、その例として翻訳や検索がある。画像は私たちにとって身近なものであり、ベクトルとして扱う。音もデータとして扱うことができる。音は人間の声、音楽、環境音の三つに分類でき、いずれも音の波の高さを数値化すればデータとして扱うことができる。その例として音声認識や楽曲分析、環境音認識が挙げられる。他の事例としてパターン認識がある。パターン認識とは画像や音声、テキストなど、様々なデータを対象として、それが「何」であるかを当てる方法である。例として病気診断や行動認識が挙げられる。ただ、認識できる対象(クラス)は、事前に決められている。また、機械学習にも関係しており、大量のデータを準備することで分類をする(境界線を引く)ことができる。\\n'\n",
      " 'L11-Q1: '\n",
      " '正確なデータを集めるために理想的な状況は全数調査である。全数調査とは調査対象をすべて調べることである。この対象を母集団と呼ぶ。このとき調査の結果は真実になるが、この調査を行うのは実質不可能であり、労力が大きい。母集団の一部を取り出して調査することを標本調査という。標本の抽出には有意抽出法と無作為抽出法の2種類がある。有意抽出法はデータが収集しやすいがバイアスがかかる可能性がある。だから、ランダムに抽出する単純無作為抽出法や多段抽出法が良い。また、その他のバイアスとして過去から未来の予測、生存者バイアス、差別がある。個人情報保護法は個人情報を保護するためにあり、個人情報は特定の個人を識別することができるものである。個人情報の第三者提供は同意なしでは不可だが、例外もある。オープンデータとは市民や企業が使いやすい公共データである。その目的として諸課題の解決、経済の活性化、行政の高度化効率化などがある。オープンデータというには二次利用のための条件を掲載し、機械判読に適した形式で、無償提供するという形をとる必要がある。その例としてクリエイティブコモンズライセンスをつけるなどが当てはまる。\\n'\n",
      " 'L12-Q1: '\n",
      " 'データ分析においてベクトルは重要な要素である。数学的には厳密ではないが、ベクトルは数字のかたまりであり、その順番にも意味を持つ。ベクトル=データとして扱う際にそのデータ間の距離と類似度を測ることでデータ分析を行う。その例としてクラスタリング、異常検知、判定などがある。データの距離の種類にはユークリッド距離、ハミング距離、Max距離、編集距離がある。類似度にはjaccard係数、コサイン類似度がある。\\n'\n",
      " 'L13-Q1: '\n",
      " '可視化とはデータを直感的に理解できる図にすること。可視化手法の具体例としてヒストグラム、箱ひげ図、棒グラフ、パイチャート、散布図、ヒートマップ、折れ線グラフ、無向/有向グラフなどがる。可視化における注意点として目的と条件によって適切なものを選択する必要がある。2次元のデータは平面として扱えるが、それ以上の要素数になると表せないので2次元まで削る必要がある。可視化からデータ分析につながる。\\n'\n",
      " 'L14-Q1: '\n",
      " '相関は二つの関係性を説明する方法。分布はどんなデータがどのくらいあるか。相関は正の相関、負の相関、無相関がある。相関係数によって分布をみる。統計的検定による推定\\n'\n",
      " 'L15-Q1: NaN')\n"
     ]
    }
   ],
   "source": [
    "out = str(Q1_data.__getitem__(idx)[\"input_text\"])\n",
    "pp.pprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9531a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testcase でのデータ内容を確認\n",
    "Q1_data = GradePredictionDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    question_filter=[1],\n",
    "    concatenate=True,\n",
    "    mode=\"train\",\n",
    "    testcase=True,\n",
    ")\n",
    "Q1_data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('生命の起源 [SEP] '\n",
      " 'オパーリンの唱えた化学進化説ではその第一段階として「窒素誘導体の形成」が行なわれると仮説していた。それを実験的に検証したのが1953年、シカゴ大学のハロルド・ユーリーの研究室に属していたスタンリー・ミラーの行なった実験である。\\n'\n",
      " '1953年に化学的進化説上の仮説を検証する実験を行ったスタンリー・ミラーはその時どの大学にいましたか？')\n"
     ]
    }
   ],
   "source": [
    "out = str(Q1_data.__getitem__(idx)[\"input_text\"])\n",
    "pp.pprint(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'シカゴ大学'\n"
     ]
    }
   ],
   "source": [
    "ans = str(Q1_data.__getitem__(idx)[\"grades\"])\n",
    "pp.pprint(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util import load_model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import model summary\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c8840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testcase = true の場合 collate_fn の動作を確認\n",
    "input = collate_fn(Q1_data, tokenizer=tokenizer, question_filter=[1], testcase=True)\n",
    "pp.pprint(input[\"input_text\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea65c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input[\"input_ids\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode\n",
    "decoded_text = tokenizer.decode(input[\"input_ids\"][0], skip_special_tokens=True)\n",
    "pp.pprint(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util import load_model\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import model summary\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Loading model from 'elyza/Llama-3-ELYZA-JP-8B' to device cuda:0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342a2a894b364f45ab6ca153e2237be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Loading processor (use_fast=True)...\n",
      "✅ Model and processor loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36e489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "LlamaForCausalLM                              --\n",
       "├─LlamaModel: 1-1                             --\n",
       "│    └─Embedding: 2-1                         525,336,576\n",
       "│    └─ModuleList: 2-2                        --\n",
       "│    │    └─LlamaDecoderLayer: 3-1            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-2            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-3            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-4            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-5            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-6            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-7            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-8            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-9            218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-10           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-11           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-12           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-13           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-14           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-15           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-16           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-17           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-18           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-19           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-20           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-21           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-22           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-23           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-24           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-25           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-26           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-27           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-28           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-29           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-30           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-31           218,112,000\n",
       "│    │    └─LlamaDecoderLayer: 3-32           218,112,000\n",
       "│    └─LlamaRMSNorm: 2-3                      4,096\n",
       "│    └─LlamaRotaryEmbedding: 2-4              --\n",
       "├─Linear: 1-2                                 525,336,576\n",
       "======================================================================\n",
       "Total params: 8,030,261,248\n",
       "Trainable params: 8,030,261,248\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:This is a debug message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.debug(\"This is a debug message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Collate: 301 samples, max_tokens=4096\n",
      "DEBUG:__main__:prompt sample:\n",
      "[INST] あなたは大学の教授であり，学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み，成績を A, B, C, D, F のいずれかに分類してください。\n",
      "L は講義回，Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は，\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "\n",
      "です．回答が NaN の場合は未回答です。\n",
      "上記を踏まえ，出力には A/B/C/D/F のいずれか **1 文字のみ** を返してください。\n",
      "アンケート内容：\n",
      "\n",
      "L01-Q1: 情報伝達の歴史について 〇or✖のようなシンプルな情報伝達から取り決めによってより具体的に事物を伝えられるようになり、機械の発達で高速化した。\n",
      "L02-Q1: 語頭符号について\n",
      "L03-Q1: ハミング距離の理論によってビットの誤りを修正できる。\n",
      "L04-Q1: 情報漏洩を防ぐために暗号化は大事\n",
      "L05-Q1: アルゴリズムについて アルゴリズムとは問題を解決するための手順や計算方法のこと アルゴリズム体操もおなじ手順を繰り返している!!!\n",
      "L06-Q1: より少ない手順で符号を並び替\n",
      "DEBUG:__main__:Truncating prompt: 7435 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 9691 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4835 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4905 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 7255 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 5317 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 5368 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4772 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4486 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4282 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 5428 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4666 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 7509 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4563 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 9732 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 6096 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 4108 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 8307 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 7323 + 2 > 4096\n",
      "DEBUG:__main__:Truncating prompt: 6291 + 2 > 4096\n",
      "INFO:__main__:Tokenize done: \n"
     ]
    }
   ],
   "source": [
    "input = collate_fn(Q1_data, tokenizer=tokenizer, question_filter=[1], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c78ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[\"input_ids\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputの内容をdecodeして確認\n",
    "decoded_input = tokenizer.decode(input[\"input_ids\"][0], skip_special_tokens=True)\n",
    "print(decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3457164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "## 生成\n",
    "model.eval()\n",
    "ids = input[\"input_ids\"][0].unsqueeze(0).to(model.device)\n",
    "attention_mask = input[\"attention_mask\"][0].unsqueeze(0).to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids=ids,\n",
    "        attention_mask= attention_mask,\n",
    "        max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42af97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "[INST] あなたは大学の教授であり，学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み，成績を A, B, C, D, F のいずれかに分類してください。\n",
      "L は講義回，Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は，\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "\n",
      "です．回答が NaN の場合は未回答です。\n",
      "上記を踏まえ，出力には A/B/C/D/F のいずれか **1 文字のみ** を返してください。\n",
      "アンケート内容：\n",
      "\n",
      "L01-Q1: 情報伝達の歴史について 〇or✖のようなシンプルな情報伝達から取り決めによってより具体的に事物を伝えられるようになり、機械の発達で高速化した。\n",
      "L02-Q1: 語頭符号について\n",
      "L03-Q1: ハミング距離の理論によってビットの誤りを修正できる。\n",
      "L04-Q1: 情報漏洩を防ぐために暗号化は大事\n",
      "L05-Q1: アルゴリズムについて アルゴリズムとは問題を解決するための手順や計算方法のこと アルゴリズム体操もおなじ手順を繰り返している!!!\n",
      "L06-Q1: より少ない手順で符号を並び替える方法とその大切さ\n",
      "L07-Q1: ソートについて\n",
      "L08-Q1: 情報の検索について\n",
      "L09-Q1: データの整理と生活とコンピュータの共同、かかわり\n",
      "L10-Q1: 言語などの構造化されていないデータの処理に行いて\n",
      "L11-Q1: 情報の様々な抽出方法 情報をオープンデータにするためには、クリエイティブ・コモンズ・ライセンスをつけて公開しなければいけない。\n",
      "L12-Q1: データの解析において様々な距離の種類があり、用途が異なる 距離と類似度は反対の概念\n",
      "L13-Q1: データを数値化、可視化することの利点と表現方法の注意 3Dパイチャートはあまりよくない\n",
      "L14-Q1: さまざまなフィルタ処理で画質を良くしている 画像処理と芸工で学ぶ技術は密接に関係している\n",
      "L15-Q1: NaN\n",
      "[/INST]\n",
      " Cassistantassistant\n"
     ]
    }
   ],
   "source": [
    "# Decode the generated output\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Generated text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ef193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
