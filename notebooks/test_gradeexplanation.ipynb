{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e967348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421ea8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be05292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gradeexplanation_data import GradeExplanationDataset, GradeExplanationCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cd6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elyza/Llama-3-ELYZA-JP-8B tokenizerのロード\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"elyza/Llama-3-ELYZA-JP-8B\")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "#! pad_token が無い場合だけ追加\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "#! 語彙サイズを合わせる\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fc9515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.gradeexplanation_data' from '/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src\n",
    "\n",
    "importlib.reload(src.gradeexplanation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81892d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd().parent\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "data = GradeExplanationDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b174f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5081305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史',\n",
       "  'Q2': '情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'フランスの腕木通信は知らなかったのでおもしろいと思いました。'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号',\n",
       "  'Q2': '符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。',\n",
       "  'Q3': '最適符号の定義',\n",
       "  'Q4': '平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。',\n",
       "  'Q5': '前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量',\n",
       "  'Q2': '情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい',\n",
       "  'Q3': '曖昧さ=log の証明',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'エントロピーがまだよくわかっていないので、しっかり復習したいです'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量',\n",
       "  'Q2': '誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、',\n",
       "  'Q3': '通信路符号化定理、検査ビット',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム',\n",
       "  'Q2': 'アルゴリズムの定義について',\n",
       "  'Q3': '根付き木がまだよく分からなかった。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート',\n",
       "  'Q2': 'それぞれのソートのやり方',\n",
       "  'Q3': 'ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索',\n",
       "  'Q2': 'マージソートのやり方、二分探索のアルゴリズム',\n",
       "  'Q3': 'キーワードの二分探索がちょっと微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '線形探索と比べて、二分探索の計算量の少なさに驚きました。'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング',\n",
       "  'Q2': 'データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと',\n",
       "  'Q2': '人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細',\n",
       "  'Q3': 'オープン戦略のあたりがまだ曖昧です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用',\n",
       "  'Q2': '非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用',\n",
       "  'Q3': 'とくにないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権',\n",
       "  'Q2': 'データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方',\n",
       "  'Q3': 'オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用',\n",
       "  'Q2': 'ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用',\n",
       "  'Q3': 'max距離の使い方とコサイン類似度が微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方',\n",
       "  'Q2': '棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点',\n",
       "  'Q3': '多次元データの可視化',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出',\n",
       "  'Q2': '相関係数の求め方、相関や分散や統計的検定の特徴',\n",
       "  'Q3': '微分フィルタ、ソーベルフィルタ',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト',\n",
       "  'Q2': 'ラプラシアンフィルタについて',\n",
       "  'Q3': 'NaN',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。'},\n",
       " 'input_text': 'L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\\nL1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\\nL1-Q3: 特にないです\\nL1-Q4: NaN\\nL1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\\nL2-Q1: 情報源とその符号化、望ましい符号\\nL2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\\nL2-Q3: 最適符号の定義\\nL2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\\nL2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\\nL3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\\nL3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\\nL3-Q3: 曖昧さ=log の証明\\nL3-Q4: 特にないです\\nL3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\\nL4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\\nL4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\\nL4-Q3: 通信路符号化定理、検査ビット\\nL4-Q4: NaN\\nL4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\\nL5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\\nL5-Q2: アルゴリズムの定義について\\nL5-Q3: 根付き木がまだよく分からなかった。\\nL5-Q4: NaN\\nL5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\\nL6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\\nL6-Q2: それぞれのソートのやり方\\nL6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\\nL6-Q4: NaN\\nL6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\\nL7-Q1: マージソート、二分探索\\nL7-Q2: マージソートのやり方、二分探索のアルゴリズム\\nL7-Q3: キーワードの二分探索がちょっと微妙です\\nL7-Q4: NaN\\nL7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\\nL8-Q1: データとは、データの種類、予測、発見、グルーピング\\nL8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\\nL8-Q3: 特にないです\\nL8-Q4: 特にないです\\nL8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\\nL9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\\nL9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\\nL9-Q3: オープン戦略のあたりがまだ曖昧です\\nL9-Q4: NaN\\nL9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\\nL10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\\nL10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\\nL10-Q3: とくにないです\\nL10-Q4: NaN\\nL10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\\nL11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\\nL11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\\nL11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\\nL11-Q4: NaN\\nL11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\\nL12-Q1: ベクトル、距離、類似度、それらの種類や応用\\nL12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\\nL12-Q3: max距離の使い方とコサイン類似度が微妙です\\nL12-Q4: NaN\\nL12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\\nL13-Q1: データの可視化、そのいろいろなやり方\\nL13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\\nL13-Q3: 多次元データの可視化\\nL13-Q4: NaN\\nL13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\\nL14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\\nL14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\\nL14-Q3: 微分フィルタ、ソーベルフィルタ\\nL14-Q4: NaN\\nL14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\\nL15-Q1: 画像処理の補足、期末テスト\\nL15-Q2: ラプラシアンフィルタについて\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 31\n",
    "data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d106c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_data = GradeExplanationDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    question_filter=[1],\n",
    "    tokenizer=tokenizer,\n",
    "    max_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d488c611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト'},\n",
       " 'input_text': 'L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\\nL2-Q1: 情報源とその符号化、望ましい符号\\nL3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\\nL4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\\nL5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\\nL6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\\nL7-Q1: マージソート、二分探索\\nL8-Q1: データとは、データの種類、予測、発見、グルーピング\\nL9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\\nL10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\\nL11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\\nL12-Q1: ベクトル、距離、類似度、それらの種類や応用\\nL13-Q1: データの可視化、そのいろいろなやり方\\nL14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\\nL15-Q1: 画像処理の補足、期末テスト'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_data.__len__()\n",
    "Q1_data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7ed454",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Q1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42557042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\n",
      "L1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\n",
      "L1-Q3: 特にないです\n",
      "L1-Q4: NaN\n",
      "L1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\n",
      "L2-Q1: 情報源とその符号化、望ましい符号\n",
      "L2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\n",
      "L2-Q3: 最適符号の定義\n",
      "L2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\n",
      "L2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\n",
      "L3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\n",
      "L3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\n",
      "L3-Q3: 曖昧さ=log の証明\n",
      "L3-Q4: 特にないです\n",
      "L3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\n",
      "L4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\n",
      "L4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\n",
      "L4-Q3: 通信路符号化定理、検査ビット\n",
      "L4-Q4: NaN\n",
      "L4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\n",
      "L5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\n",
      "L5-Q2: アルゴリズムの定義について\n",
      "L5-Q3: 根付き木がまだよく分からなかった。\n",
      "L5-Q4: NaN\n",
      "L5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\n",
      "L6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\n",
      "L6-Q2: それぞれのソートのやり方\n",
      "L6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\n",
      "L6-Q4: NaN\n",
      "L6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\n",
      "L7-Q1: マージソート、二分探索\n",
      "L7-Q2: マージソートのやり方、二分探索のアルゴリズム\n",
      "L7-Q3: キーワードの二分探索がちょっと微妙です\n",
      "L7-Q4: NaN\n",
      "L7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\n",
      "L8-Q1: データとは、データの種類、予測、発見、グルーピング\n",
      "L8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\n",
      "L8-Q3: 特にないです\n",
      "L8-Q4: 特にないです\n",
      "L8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\n",
      "L9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\n",
      "L9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\n",
      "L9-Q3: オープン戦略のあたりがまだ曖昧です\n",
      "L9-Q4: NaN\n",
      "L9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\n",
      "L10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\n",
      "L10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\n",
      "L10-Q3: とくにないです\n",
      "L10-Q4: NaN\n",
      "L10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\n",
      "L11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\n",
      "L11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\n",
      "L11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\n",
      "L11-Q4: NaN\n",
      "L11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\n",
      "L12-Q1: ベクトル、距離、類似度、それらの種類や応用\n",
      "L12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\n",
      "L12-Q3: max距離の使い方とコサイン類似度が微妙です\n",
      "L12-Q4: NaN\n",
      "L12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\n",
      "L13-Q1: データの可視化、そのいろいろなやり方\n",
      "L13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\n",
      "L13-Q3: 多次元データの可視化\n",
      "L13-Q4: NaN\n",
      "L13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\n",
      "L14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\n",
      "L14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\n",
      "L14-Q3: 微分フィルタ、ソーベルフィルタ\n",
      "L14-Q4: NaN\n",
      "L14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\n",
      "L15-Q1: 画像処理の補足、期末テスト\n",
      "L15-Q2: ラプラシアンフィルタについて\n",
      "L15-Q3: NaN\n",
      "L15-Q4: NaN\n",
      "L15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。\n",
      "\n",
      " input_text length: 1995\n"
     ]
    }
   ],
   "source": [
    "# data内のinputtextを確認\n",
    "print(data.__getitem__(idx)[\"input_text\"])\n",
    "print(f\"\\n input_text length: {len(tokenizer.encode(data.__getitem__(idx)['input_text']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616b5ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_dataset keys: ['userid', 'labels', 'grades', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', 'L11', 'L12', 'L13', 'L14', 'L15', 'input_text', 'target']\n",
      "Sample: {'userid': 'C-2021-1_U1', 'labels': 4, 'grades': 'F', 'L1': {'Q1': '情報伝達には声、モールス信号など様々な形があり、人類の進化と共により高度に精度が高められてきた。', 'Q2': '0と1が情報伝達において使われるということは高校の情報でも学んだことですが、この授業でより深く多面的に学ぶことができました。', 'Q3': '電子教科書を使うのが久しぶりだったので、戸惑う場面がありました。', 'Q4': 'NaN', 'Q5': '授業中に使用されているスライドが簡潔で理解しやすいです。次はもっと電子教科書を使いこなせるようにしたいです。'}, 'L2': {'Q1': '情報源符号化とは、情報を黒と白の○で表すことで、複合とは符号化によって得られたものを元に戻す作業のことである。それらの過程の中で、平均符号語長を短くすることが目指される。そこで一意符号可能性と瞬時復号可能性を持つ語頭符号を用いる。 エントロピーとは平均符号語長の下限のことである。', 'Q2': '確率やlogなど高校時代に学習した数学の知識が出てきたが、ぎりぎり思い出しながら授業を受けることができた。', 'Q3': '情報源符号化定理で、Sの最適符号C*の平均符号語長がエントロピーとエントロピー+1の値の間に収まるのかがあまりよく分からなかったです。', 'Q4': 'NaN', 'Q5': '今日の内容は文系の私でもぎりぎり理解できました。今日の内容を忘れないうちに演習問題に取り組んで知識を定着させておこうと思います。'}, 'L3': {'Q1': '生起確率pの事象の生起を知ったことによる曖昧さの減少量は情報量と一致し、生起確率pが高いほど情報量は現状しまた逆もしかりである。またエントロピーは情報量の期待値と一致する。相互情報量とは、ある事象2つが相互に関連して生起した場合に得られる情報量のことである。', 'Q2': 'エントロピーは情報量と曖昧さの減少量に関連する。PrはPriorityで確率を示すものである。|は条件付き確率を示すときに使われる。', 'Q3': '相互情報量の求め方をまだ理解していないので復習する。', 'Q4': 'NaN', 'Q5': '予習するときはスライドを見るだけでなく演習問題にも取り組んでおこうと思った。今回予習はしていったが、演習問題は解かなかった。しかし、大学受験から2年以上経ち数学の知識がほとんど抜けた今の状態では全く追いつけないので先に演習問題にも取り組んでおかなければならないと痛感した。'}, 'L4': {'Q1': '通信の際に符号の誤りを検出・訂正する仕組みについて学んだ。符号の誤りは、符号語同士がs+1以上離れていればs個検出でき、2t+1離れていればt個訂正することができる。また、その距離をハミング距離と言う。', 'Q2': 'ハミング距離は符号同士の異なっている点の数のことだと理解した。', 'Q3': '特にないです。', 'Q4': 'LGCへの投稿を情報科学の欄にしたのですが、他の投稿がやっている授業内容と違っていて、自分がきちんと投稿できているのか不安です。', 'Q5': '定理を理解するのが難しいと感じたので、とりあえず定理を理解する前にそういうものだと思い、あとからじっくり理解するようにしようと思った。'}, 'L5': {'Q1': 'コンピューターサイエンスは計算機科学であるともされ、全ての科学技術分野の基盤となりうるものである。コンピューター上で行われている全てのことは「計算」であり、コンピューターサイエンスはそれを制御・理解するための科学である。 アルゴリズムとは、関数の計算方法を示す手続きのことを言い、プログラムとはアルゴリズムをコンピューターが分かる言葉で記述したものである。アルゴリズムを上手く考えることができれば、「偽コイン発見」の問題のように作業を効率化・最適化することができる。大きな数の因数分解は難しいため、ユークリッドの互除法を用いれば容易に計算できる。', 'Q2': 'アルゴリズムとプログラムの違いはなんであるか前々から疑問であったが、今回の授業で両者の違いと関連性についてはっきり理解することができた。', 'Q3': 'やはり、計算や数学の知識が必要になる点になると途端に理解が追いつかなくなってしまう。', 'Q4': 'NaN', 'Q5': '次回はより時間をかけて予習をしてから授業に臨みたいと思う。'}, 'L6': {'Q1': '計算ステップ数とは、アルゴリズムが終了するまでに行われる演算の数である。最大公約数の問題では剰余を考える。バブルソートとは、隣り合う要素の大小を比較しながら昇順もしくは降順に整列していくことである。2進木のソートを読むときには通りがけ順で、左の子→自分→右の子、の順番で読む。2進木の一種にヒープがある。', 'Q2': 'バブルソートは高校の授業で知っていたが、他のソートは知らなかった。今回は授業の内容の大体を把握することができたと思う。', 'Q3': 'なぜこういったソートの種類が複数あるのかが分からないので、これから課題に取り組む内に見つけようと思う。', 'Q4': 'NaN', 'Q5': '今回の授業は大体を理解できたが、分かっていないところが少しあるのでしっかりと復習する。また、来週はより丁寧に予習をしてから、授業に臨もうと思う。'}, 'L7': {'Q1': 'マージソートとは、入力数列を分割していき、分割したものを整列して統合(マージ)するアルゴリズムである。ヒープソートと同様にO(nlogn)回の比較で要素を整列する。2進木を使用しないためよりシンプルである。最悪時の比較回数は決定木の高さに等しい。 線形探索が数列を先頭から探索していくのに対し、二部探索は真ん中の要素から比較して前半部分・後半部分のどちらか選んで探索していくものである。なので、後者の方が圧倒的に速い。', 'Q2': 'ヒープソートと二部探索はだいたいの仕組みを理解することができた。計算も、考えてみればよく分かるものが多く、復習すればより定着させることが出来ると思う。', 'Q3': 'テキストの二部探索がよくわからなかった。接尾辞からどう探索していくのかがいまいち分かっていない。', 'Q4': 'NaN', 'Q5': 'LGCに記事を載せられるほどまだ理解していないので、すぐに復習するようにします。'}, 'L8': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L9': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L10': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L11': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L12': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L13': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L14': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L15': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'input_text': 'L1-Q1: 情報伝達には声、モールス信号など様々な形があり、人類の進化と共により高度に精度が高められてきた。\\nL1-Q2: 0と1が情報伝達において使われるということは高校の情報でも学んだことですが、この授業でより深く多面的に学ぶことができました。\\nL1-Q3: 電子教科書を使うのが久しぶりだったので、戸惑う場面がありました。\\nL1-Q4: NaN\\nL1-Q5: 授業中に使用されているスライドが簡潔で理解しやすいです。次はもっと電子教科書を使いこなせるようにしたいです。\\nL2-Q1: 情報源符号化とは、情報を黒と白の○で表すことで、複合とは符号化によって得られたものを元に戻す作業のことである。それらの過程の中で、平均符号語長を短くすることが目指される。そこで一意符号可能性と瞬時復号可能性を持つ語頭符号を用いる。 エントロピーとは平均符号語長の下限のことである。\\nL2-Q2: 確率やlogなど高校時代に学習した数学の知識が出てきたが、ぎりぎり思い出しながら授業を受けることができた。\\nL2-Q3: 情報源符号化定理で、Sの最適符号C*の平均符号語長がエントロピーとエントロピー+1の値の間に収まるのかがあまりよく分からなかったです。\\nL2-Q4: NaN\\nL2-Q5: 今日の内容は文系の私でもぎりぎり理解できました。今日の内容を忘れないうちに演習問題に取り組んで知識を定着させておこうと思います。\\nL3-Q1: 生起確率pの事象の生起を知ったことによる曖昧さの減少量は情報量と一致し、生起確率pが高いほど情報量は現状しまた逆もしかりである。またエントロピーは情報量の期待値と一致する。相互情報量とは、ある事象2つが相互に関連して生起した場合に得られる情報量のことである。\\nL3-Q2: エントロピーは情報量と曖昧さの減少量に関連する。PrはPriorityで確率を示すものである。|は条件付き確率を示すときに使われる。\\nL3-Q3: 相互情報量の求め方をまだ理解していないので復習する。\\nL3-Q4: NaN\\nL3-Q5: 予習するときはスライドを見るだけでなく演習問題にも取り組んでおこうと思った。今回予習はしていったが、演習問題は解かなかった。しかし、大学受験から2年以上経ち数学の知識がほとんど抜けた今の状態では全く追いつけないので先に演習問題にも取り組んでおかなければならないと痛感した。\\nL4-Q1: 通信の際に符号の誤りを検出・訂正する仕組みについて学んだ。符号の誤りは、符号語同士がs+1以上離れていればs個検出でき、2t+1離れていればt個訂正することができる。また、その距離をハミング距離と言う。\\nL4-Q2: ハミング距離は符号同士の異なっている点の数のことだと理解した。\\nL4-Q3: 特にないです。\\nL4-Q4: LGCへの投稿を情報科学の欄にしたのですが、他の投稿がやっている授業内容と違っていて、自分がきちんと投稿できているのか不安です。\\nL4-Q5: 定理を理解するのが難しいと感じたので、とりあえず定理を理解する前にそういうものだと思い、あとからじっくり理解するようにしようと思った。\\nL5-Q1: コンピューターサイエンスは計算機科学であるともされ、全ての科学技術分野の基盤となりうるものである。コンピューター上で行われている全てのことは「計算」であり、コンピューターサイエンスはそれを制御・理解するための科学である。 アルゴリズムとは、関数の計算方法を示す手続きのことを言い、プログラムとはアルゴリズムをコンピューターが分かる言葉で記述したものである。アルゴリズムを上手く考えることができれば、「偽コイン発見」の問題のように作業を効率化・最適化することができる。大きな数の因数分解は難しいため、ユークリッドの互除法を用いれば容易に計算できる。\\nL5-Q2: アルゴリズムとプログラムの違いはなんであるか前々から疑問であったが、今回の授業で両者の違いと関連性についてはっきり理解することができた。\\nL5-Q3: やはり、計算や数学の知識が必要になる点になると途端に理解が追いつかなくなってしまう。\\nL5-Q4: NaN\\nL5-Q5: 次回はより時間をかけて予習をしてから授業に臨みたいと思う。\\nL6-Q1: 計算ステップ数とは、アルゴリズムが終了するまでに行われる演算の数である。最大公約数の問題では剰余を考える。バブルソートとは、隣り合う要素の大小を比較しながら昇順もしくは降順に整列していくことである。2進木のソートを読むときには通りがけ順で、左の子→自分→右の子、の順番で読む。2進木の一種にヒープがある。\\nL6-Q2: バブルソートは高校の授業で知っていたが、他のソートは知らなかった。今回は授業の内容の大体を把握することができたと思う。\\nL6-Q3: なぜこういったソートの種類が複数あるのかが分からないので、これから課題に取り組む内に見つけようと思う。\\nL6-Q4: NaN\\nL6-Q5: 今回の授業は大体を理解できたが、分かっていないところが少しあるのでしっかりと復習する。また、来週はより丁寧に予習をしてから、授業に臨もうと思う。\\nL7-Q1: マージソートとは、入力数列を分割していき、分割したものを整列して統合(マージ)するアルゴリズムである。ヒープソートと同様にO(nlogn)回の比較で要素を整列する。2進木を使用しないためよりシンプルである。最悪時の比較回数は決定木の高さに等しい。 線形探索が数列を先頭から探索していくのに対し、二部探索は真ん中の要素から比較して前半部分・後半部分のどちらか選んで探索していくものである。なので、後者の方が圧倒的に速い。\\nL7-Q2: ヒープソートと二部探索はだいたいの仕組みを理解することができた。計算も、考えてみればよく分かるものが多く、復習すればより定着させることが出来ると思う。\\nL7-Q3: テキストの二部探索がよくわからなかった。接尾辞からどう探索していくのかがいまいち分かっていない。\\nL7-Q4: NaN\\nL7-Q5: LGCに記事を載せられるほどまだ理解していないので、すぐに復習するようにします。\\nL8-Q1: NaN\\nL8-Q2: NaN\\nL8-Q3: NaN\\nL8-Q4: NaN\\nL8-Q5: NaN\\nL9-Q1: NaN\\nL9-Q2: NaN\\nL9-Q3: NaN\\nL9-Q4: NaN\\nL9-Q5: NaN\\nL10-Q1: NaN\\nL10-Q2: NaN\\nL10-Q3: NaN\\nL10-Q4: NaN\\nL10-Q5: NaN\\nL11-Q1: NaN\\nL11-Q2: NaN\\nL11-Q3: NaN\\nL11-Q4: NaN\\nL11-Q5: NaN\\nL12-Q1: NaN\\nL12-Q2: NaN\\nL12-Q3: NaN\\nL12-Q4: NaN\\nL12-Q5: NaN\\nL13-Q1: NaN\\nL13-Q2: NaN\\nL13-Q3: NaN\\nL13-Q4: NaN\\nL13-Q5: NaN\\nL14-Q1: NaN\\nL14-Q2: NaN\\nL14-Q3: NaN\\nL14-Q4: NaN\\nL14-Q5: NaN\\nL15-Q1: NaN\\nL15-Q2: NaN\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: NaN', 'target': 'この学生の成績は、Fです。理由は、講義の後半においてアンケートが未回答であり、学習の継続や理解の確認が行われていないためです。前半の講義では理解を示す回答も見られましたが、後半の講義においては参加や理解の確認がされていないことが成績に影響しています。'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "target_dataset = torch.load(\n",
    "    DATA_PATH / \"GradeExplanationDataset_Qs5_trimmed.pt\", weights_only=False\n",
    ")\n",
    "print(f\"target_dataset keys: {list(target_dataset[0].keys())}\")\n",
    "print(f\"Sample: {target_dataset[0]}\")\n",
    "\n",
    "# target_dataset内のuseridをキーにして，targetをdataに追加する\n",
    "def add_target_to_data(\n",
    "    data: GradeExplanationDataset, target_dataset\n",
    ") -> GradeExplanationDataset:\n",
    "    # Build a mapping from userid to target\n",
    "    userid_to_target = {item[\"userid\"]: item[\"target\"] for item in target_dataset}\n",
    "    for i in range(len(data)):\n",
    "        user_id = data[i][\"userid\"]\n",
    "        if user_id in userid_to_target:\n",
    "            data[i][\"target\"] = userid_to_target[user_id]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dd6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_target_to_data(data, target_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa7fa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\n",
      "L1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\n",
      "L1-Q3: 特にないです\n",
      "L1-Q4: NaN\n",
      "L1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\n",
      "L2-Q1: 情報源とその符号化、望ましい符号\n",
      "L2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\n",
      "L2-Q3: 最適符号の定義\n",
      "L2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\n",
      "L2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\n",
      "L3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\n",
      "L3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\n",
      "L3-Q3: 曖昧さ=log の証明\n",
      "L3-Q4: 特にないです\n",
      "L3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\n",
      "L4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\n",
      "L4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\n",
      "L4-Q3: 通信路符号化定理、検査ビット\n",
      "L4-Q4: NaN\n",
      "L4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\n",
      "L5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\n",
      "L5-Q2: アルゴリズムの定義について\n",
      "L5-Q3: 根付き木がまだよく分からなかった。\n",
      "L5-Q4: NaN\n",
      "L5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\n",
      "L6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\n",
      "L6-Q2: それぞれのソートのやり方\n",
      "L6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\n",
      "L6-Q4: NaN\n",
      "L6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\n",
      "L7-Q1: マージソート、二分探索\n",
      "L7-Q2: マージソートのやり方、二分探索のアルゴリズム\n",
      "L7-Q3: キーワードの二分探索がちょっと微妙です\n",
      "L7-Q4: NaN\n",
      "L7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\n",
      "L8-Q1: データとは、データの種類、予測、発見、グルーピング\n",
      "L8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\n",
      "L8-Q3: 特にないです\n",
      "L8-Q4: 特にないです\n",
      "L8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\n",
      "L9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\n",
      "L9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\n",
      "L9-Q3: オープン戦略のあたりがまだ曖昧です\n",
      "L9-Q4: NaN\n",
      "L9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\n",
      "L10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\n",
      "L10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\n",
      "L10-Q3: とくにないです\n",
      "L10-Q4: NaN\n",
      "L10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\n",
      "L11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\n",
      "L11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\n",
      "L11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\n",
      "L11-Q4: NaN\n",
      "L11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\n",
      "L12-Q1: ベクトル、距離、類似度、それらの種類や応用\n",
      "L12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\n",
      "L12-Q3: max距離の使い方とコサイン類似度が微妙です\n",
      "L12-Q4: NaN\n",
      "L12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\n",
      "L13-Q1: データの可視化、そのいろいろなやり方\n",
      "L13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\n",
      "L13-Q3: 多次元データの可視化\n",
      "L13-Q4: NaN\n",
      "L13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\n",
      "L14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\n",
      "L14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\n",
      "L14-Q3: 微分フィルタ、ソーベルフィルタ\n",
      "L14-Q4: NaN\n",
      "L14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\n",
      "L15-Q1: 画像処理の補足、期末テスト\n",
      "L15-Q2: ラプラシアンフィルタについて\n",
      "L15-Q3: NaN\n",
      "L15-Q4: NaN\n",
      "L15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。\n",
      "この学生の成績は、Aです。理由は、質問1と質問2において、講義内容を具体的かつ詳細に説明しており、特に情報の基本概念やアルゴリズム、データ分析手法について深い理解を示しているためです。また、質問3での不明点を具体的に挙げ、質問4で積極的に質問をする姿勢が見られ、学習意欲が高いことが伺えます。質問5では、講義内容に対する興味や新しい知識の習得に対する前向きな姿勢が示されており、全体的に優れた学習態度が評価されます。\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "print(data.__getitem__(idx)[\"input_text\"])\n",
    "print(data.__getitem__(idx)[\"target\"])\n",
    "print(data.__getitem__(idx)[\"grades\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f379242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 15:18:55,091 : src.util : INFO : 58 : Test_message\n",
      "2025-06-18 15:18:55,092 : src.util : INFO : 604 : Questions: [1, 2, 3, 4, 5], Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "\n",
      "2025-06-18 15:18:55,093 : src.util : INFO : 619 : preamble set:\n",
      "================\n",
      "あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\n",
      "さらに、その成績を決定した根拠を簡潔に説明してください。\n",
      "成績と根拠は出力例のような形式で出力してください。\n",
      "入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は、\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "です。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\n",
      "出力には、必ず A、B、C、D、F のいずれかを含めてください。\n",
      "出力例:\n",
      "この学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\n",
      "アンケート内容：\n",
      "================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from logging import INFO, DEBUG\n",
    "from src.util import set_logger\n",
    "\n",
    "logger = set_logger(level=DEBUG)\n",
    "\n",
    "# collatorの動作確認\n",
    "data_collator = GradeExplanationCollator(\n",
    "    tokenizer,\n",
    "    max_tokens=4096,\n",
    "    include_target=True,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2505da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 15:18:55,104 : src.util : DEBUG : 654 : prompt sample:\n",
      "[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\n",
      "さらに、その成績を決定した根拠を簡潔に説明してください。\n",
      "成績と根拠は出力例のような形式で出力してください。\n",
      "入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は、\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "です。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\n",
      "出力には、必ず A、B、C、D、F のいずれかを含めてください。\n",
      "出力例:\n",
      "この学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\n",
      "アンケート内容：\n",
      "\n",
      "L1-Q1: イントロダ\n",
      "2025-06-18 15:18:55,104 : src.util : DEBUG : 655 : target sample: この学生の成績は、Dです。理由は、質問15-2および15-5において、期末テストにおいて時間が足りず\n",
      "2025-06-18 15:18:55,113 : src.util : DEBUG : 667 : Tokenization Done\n",
      "/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py:692: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_ids[i, -len(ids) :] = torch.tensor(ids)\n",
      "/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py:693: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_lbl[i, -len(lbl) :] = torch.tensor(lbl)\n",
      "2025-06-18 15:18:55,116 : src.util : DEBUG : 704 : Collating Done\n",
      "2025-06-18 15:18:55,116 : src.util : DEBUG : 706 : Collate: 2 samples, max_tokens=4096\n",
      "2025-06-18 15:18:55,118 : src.util : INFO : 10 : Batch keys: dict_keys(['input_ids', 'attention_mask', 'labels', 'target_ids'])\n",
      "2025-06-18 15:18:55,119 : src.util : INFO : 14 : Batch key: input_ids, value shape: torch.Size([2, 3990])\n",
      "2025-06-18 15:18:55,119 : src.util : INFO : 14 : Batch key: attention_mask, value shape: torch.Size([2, 3990])\n",
      "2025-06-18 15:18:55,120 : src.util : INFO : 14 : Batch key: labels, value shape: torch.Size([2, 3990])\n",
      "2025-06-18 15:18:55,120 : src.util : INFO : 14 : Batch key: target_ids, value shape: torch.Size([2, 114])\n",
      "2025-06-18 15:18:55,124 : src.util : INFO : 20 : Input prompt: \n",
      "['[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\n成績と根拠は出力例のような形式で出力してください。\\n入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\\nアンケートの質問文は、\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\nQ4:質問があれば書いてください\\nQ5:今日の授業の感想や反省を書いてください\\nです。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\n出力には、必ず A、B、C、D、F のいずれかを含めてください。\\n出力例:\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\nアンケート内容：\\n\\nL1-Q1: イントロダクション 情報通信方法\\nL1-Q2: 情報の通信の基本は昔と変わらないということがわかった\\nL1-Q3: NaN\\nL1-Q4: NaN\\nL1-Q5: これからの授業が楽しみなのでしっかりと学んでいきたいです\\nL2-Q1: NaN\\nL2-Q2: NaN\\nL2-Q3: NaN\\nL2-Q4: NaN\\nL2-Q5: NaN\\nL3-Q1: NaN\\nL3-Q2: NaN\\nL3-Q3: NaN\\nL3-Q4: NaN\\nL3-Q5: NaN\\nL4-Q1: NaN\\nL4-Q2: NaN\\nL4-Q3: NaN\\nL4-Q4: NaN\\nL4-Q5: NaN\\nL5-Q1: 効率のよいアルゴリズム 計算時間\\nL5-Q2: アルゴリズムがなにかを把握することができた\\nL5-Q3: 根付き木についてがよくわからなかった\\nL5-Q4: NaN\\nL5-Q5: プログラムとアルゴリズムについて知ることができた。最適なアルゴリズムをすぐに見つけ出せるようになりたい\\nL6-Q1: ユークリッドの互除法 ソートについて\\nL6-Q2: ヒープソートは2進木の欠点をなくしたものである\\nL6-Q3: NaN\\nL6-Q4: NaN\\nL6-Q5: ソートにはいろいろな種類があり始めて学ぶ内容だったので面白かった\\nL7-Q1: マージソートとはどのようなアルゴリズムか 二分深索法とは\\nL7-Q2: 二分深索は線形深索よりも少ない比較回数ですむので圧倒的に速い\\nL7-Q3: 比較ソートアルゴリズムの比較回数についてnlog_2nに比例して増えるということがわかりずらかった\\nL7-Q4: NaN\\nL7-Q5: 最近になってシンプルな比較方法が生み出されたということにおどろいた。まだまだわかっていないだけでよりよい方法があるとおもうとわくわくした。\\nL8-Q1: NaN\\nL8-Q2: NaN\\nL8-Q3: NaN\\nL8-Q4: NaN\\nL8-Q5: NaN\\nL9-Q1: NaN\\nL9-Q2: NaN\\nL9-Q3: NaN\\nL9-Q4: NaN\\nL9-Q5: NaN\\nL10-Q1: 非構造データ(文字、画像、音声など)の解析 パターン認識\\nL10-Q2: コンピュータにもを判別させることは難しいことがわかった\\nL10-Q3: パターン認識のイメージ図がわからなかった\\nL10-Q4: NaN\\nL10-Q5: 時代が進むにつれてAIが認識できる範囲も広がっていくと思うとなんだかわくわくする。\\nL11-Q1: 調査 個人情報 オープンデータ\\nL11-Q2: 全数調査のメリット・デメリット 個人情報の保護に関して\\nL11-Q3: オープンデータがどのようなものかはわかったが著作権のあたりからわからなかった\\nL11-Q4: NaN\\nL11-Q5: 全数調査ができないとき、どのような基準でデータをとっているのか知らなかったが今回しれてよかった。バイアスという言葉になじみがなくわかりにくかったがなんとか理解できたと思う。\\nL12-Q1: NaN\\nL12-Q2: NaN\\nL12-Q3: NaN\\nL12-Q4: NaN\\nL12-Q5: NaN\\nL13-Q1: 可視化についてどのグラフが適しているか、また表し方によるわかりにくさなど\\nL13-Q2: 要素を変更することによってグラフから得られるイメージを変えることができる\\nL13-Q3: NaN\\nL13-Q4: NaN\\nL13-Q5: グラフは使い方によってよりわかりやすくもできるが、適していないグラフだと理解を妨げたり間違ったイメージを与えることも可能なので慎重に用いていく必要があるなと思いました。\\nL14-Q1: 分布、分散、相関係数について統計的検定とは統計差を評価する枠組みのことである。 画像のフィルター\\nL14-Q2: 分布、分散の活用方法 画像の処理方法の種類\\nL14-Q3: 統計的検定の有意水準などの言葉の意味がわかりずらかった\\nL14-Q4: NaN\\nL14-Q5: 分布などはこれから多く見かけたり用いていくことになると思うので、しっかりと身につけておきたいです。有意水準や帰無仮説などややこしい用語が多く出て理解しずらかったがテストに向けて頑張っていきたいと思う。\\nL15-Q1: 画像のエッジに関して テスト\\nL15-Q2: 期末テストに準備して挑んだつもりだったが全く時間が足りず努力が足りなかったと痛感した。\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: 記述問題があまりうまくかけなかったので授業で習ったことを自分の言葉で言い表せるようになることが必要だと思いました。大学に入って初めてのテストでしたが力を発揮できなかったのでこれからのテストをもっと頑張ろうと思いました。\\n[/INST]\\nこの学生の成績は、Dです。理由は、質問15-2および15-5において、期末テストにおいて時間が足りず、記述問題がうまく書けなかったと述べており、テストでのパフォーマンスが低かったためです。また、質問内容全体を通して、理解が不十分な箇所が多く、特に専門用語や概念の理解に苦労している様子が見受けられます。', '[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\n成績と根拠は出力例のような形式で出力してください。\\n入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\\nアンケートの質問文は、\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\nQ4:質問があれば書いてください\\nQ5:今日の授業の感想や反省を書いてください\\nです。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\n出力には、必ず A、B、C、D、F のいずれかを含めてください。\\n出力例:\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\nアンケート内容：\\n\\nL1-Q1: 遠くに情報を伝える方法として、初めは狼煙やたいこなどで合図を送るという手段が使われていたが、文字を発明して文章を送ったり、モールス信号を発明したりすることで伝達手段を増やしていった。\\nL1-Q2: モールス信号を学ぶ楽しさを知ることができた。\\nL1-Q3: NaN\\nL1-Q4: NaN\\nL1-Q5: モールス信号についてもっと知りたいと思った。\\nL2-Q1: NaN\\nL2-Q2: NaN\\nL2-Q3: NaN\\nL2-Q4: NaN\\nL2-Q5: NaN\\nL3-Q1: 情報量が増えれば増えるほどその事象の曖昧さは減少する。また、滅多に起きない事象の生起を知ることで得られる情報量は大きい。\\nL3-Q2: 今回の授業における猫の機嫌と尻尾の関係の例を聞いて相互情報量について理解を深めることができた。\\nL3-Q3: NaN\\nL3-Q4: NaN\\nL3-Q5: 今回は数学的な考え方をすることが多くて理解を深めるのに苦しんだが、例題を解いたり、説明を聞いたりすることで理解することができた。\\nL4-Q1: 通信路を通してビット列を伝送する際、ノイズの影響によりビットの反転が起きる場合がある。この反転の対策として送信電力を大きくし信号対雑音電力比を向上させる、大型のアンテナを使い受信信号電力を向上させる、受信アンプを冷却し受信器内の熱雑音を減少させる、より広い周波数帯域を利用するなどがあるが、物理的、経済的制限によりこれらの方策が取れないことが多い。なのでもう一つの対策として符号化を工夫するというのがある。これは自動誤り検出と自動誤り訂正でビット反転があったことを検出し再送、訂正するというものだ。\\nL4-Q2: ビット列を送信する際、通信路を通して伝送するときにノイズの影響でビットの反転が起きることがあるとわかった。\\nL4-Q3: NaN\\nL4-Q4: NaN\\nL4-Q5: 今日の授業は難しいところが多く理解に苦しんだ。\\nL5-Q1: 計算には物理的アプローチとCS的アプローチがある。物理的アプローチは観測に基づいて現象を法律化するもので法律が正しいということは決して証明できないため、反例が発見されると法律は棄却されてしまう。CS的アプローチはあらゆる問題を関数の計算問題として形式化するもので、問題を解くための効率の良い計算手順を設計する。計算手順の正当性や効率化の限界は証明できる。 コンピュータが行なっていることは全て計算である。計算をうまく制御するために計算がどのようなものであるかを理解する科学がコンピュータサイエンスである。コンピュータの計算は単純な計算を組み合わせることで実現する。この組み合わせ方をアルゴリズムといい、計算の手順である。\\nL5-Q2: 偽コインを発見する問題で、9枚のコインの中から偽のコインを見つけるというもので2回天秤にかけるだけで見つけ出すことができるというやり方を自分で思いつくことができなかったので驚いた。\\nL5-Q3: NaN\\nL5-Q4: NaN\\nL5-Q5: 自分は普段何気なくコンピュータを使っているが、コンピュータの計算について知ろうと思ったり、深く考えてみたことがなかった。今後はコンピュータサイエンスの観点から計算をうまく扱えるようになりたい。\\nL6-Q1: 計算ステップ数とはアルゴリズムが終了するまでに行われる基本演算の回数のことで、計算ステップ数が少ないほどアルゴリズムの実行時間は短くなる。 n個のアイテムが与えられたときそれらをある順序によって並び替えることをソートという。ソートは計算機科学における最も基本的な問題の一つである。隣り合う要素の大小を比較しながら整列していくバブルソートや、最大の要素を探し、それと最後の要素を入れ替える選択ソートなどがある。\\nL6-Q2: 要素の比較回数、最大値の更新回数、要素の更新回数で時間計算量を見積もることができるとわかった。\\nL6-Q3: NaN\\nL6-Q4: NaN\\nL6-Q5: オーダー記法が難しくあまり理解できなかった。\\nL7-Q1: ソート問題の解法の一つとして、各節点が高々二つの子しか持たない根付き木のことである二進木がある。二進木の読み方は節点の値を左、自分、右の順に読む。二進木を使ったソートの欠点は入力数列の並び方で計算時間が変わるということだ。節点数n、高さhの二進木が、・深さdの節点がちょうど2^d個存在し、深さhの節点は左から順に存在する。・どの節点も自分の親に格納された値以下である。という二つの条件を満たすときその木をヒープという。\\nL7-Q2: 二進木を使用しない方がシンプルで見やすいことが分かった。ソートアルゴリズムは必ずO(nlogn)回の比較を要すると分かった。\\nL7-Q3: NaN\\nL7-Q4: NaN\\nL7-Q5: 二進木がすごく複雑で分かりにくかった\\nL8-Q1: 線形探索は左端からxを探していくので最悪の場合n回の要素比較をしなければならない。2分探索は真ん中の要素yとxを比較する。なので各ステップで探索する範囲は必ず1/2以下になる。つまり線形探索よりも2分探索の方が速い。\\nL8-Q2: 自分は普段から何気なくデータという単語を使っていたが、データとは何を指すかとか考えたことがなかった。授業を聞いてコンピュータ処理の対象となる記号化数字化された資料、物事の推論の基礎となる事実、情報のことであるということが分かった。\\nL8-Q3: NaN\\nL8-Q4: NaN\\nL8-Q5: データについてあまり考えたことがなかったのでデータについて学べるのがとても楽しい。また今まで数字や記号が多く出てきていて難しいなと思っていたので、今回の後半のようにわかりやすい授業は意欲が湧く。\\nL9-Q1: データ分析の基本として予測、傾向や関連の発見、分類・グルーピングがある。予測とは過去のデータの傾向や結果に基づいてデータの予想を立てることである。予測は過去のデータを集められなかったり、要因が不明な場合があったり、現時点と予測時点で状況が違う場合があったりすることから難しい時もある。発見とは相関分析や頻出パターンを使ってデータを分析することである。分類・グルーピングとはデータをいくつかのグループに分けることでデータの把握を容易にするものである。 人工知能とは人間の知能を真似する機械のことであり、大きく特化型AIと汎用AIに分かれる。特化型AIは特定の知能だけを学習したAIのことである。また、汎用AIとは人間の知能と同じ柔軟さと多機能性を持つAIのことである。ただ、まだ実現はしていないのが現状である。\\nL9-Q2: AIを活用することでビジネスもできることが分かった。人工知能をうまく活用できるようになれば、ビジネスを成功させるだけでなく、仕事を奪われることもないと分かった。\\nL9-Q3: NaN\\nL9-Q4: NaN\\nL9-Q5: 最近はAIが当たり前に身の回りにあるようになってきているが、それらのAIは人間以上の知能を持ちうるだけに、うまく活用しなければ色々なことを奪われてしまうことが分かった。\\nL10-Q1: 非構造データとは文章や画像、音がその代表例で、表形式にはならないため非構造化データと呼ばれる。非構造データ処理には言語処理や画像処理、音声音楽処理などがある。パターン認識とはさまざまなデータを対象としてそれが何であるかをコンピュータに解かせるというものだ。人間は画像の認識や音声の認識を無意識、高精度に実現可能であるが、コンピュータに理解させるのは難しい。\\nL10-Q2: 人間にとっては画像や音声を認識することはなんちゃないことで簡単だと思っていたが、コンピュータにとってはとても難しいことであるということが分かった。また、それでも最近はパターン認識が身近になっていることは技術の発展に驚いた。\\nL10-Q3: NaN\\nL10-Q4: NaN\\nL10-Q5: 人間にできることでコンピュータにできないことはもうないんじゃないかと思うほどコンピュータにできることが増えていてこれからの未来が楽しみである。\\nL11-Q1: 正確なデータに基づいて調査するために、データを集める方法として、調査対象を全て調べる全数調査が理想として挙げられる。ただし、全数調査を使える場面は、すべての母集団を調査できる環境が整っている、母集団の規模が小さいときなどに限られる。そのため、一般的に全数調査は不可能であると考えられている。メリットとしては真実のデータがとれる。全数調査が無理な場合、母集団の一部を取り出して調査する標本調査があげられる。標本調査は偏りが生まれる可能性がある。偏りが入らないようにデータを収集するために、ランダムにデータを選べばよい。 個人情報保護法による個人情報の定義とは、生存する個人に関する情報であって、氏名ら生年月日等特定の個人を識別することができるもの、個人識別符号が含まれるもののことである。オープンデータとは市民や企業が使いやすい公共データのことである。ただし、ホームページで公開しているものがオープンデータというわけではない。\\nL11-Q2: オープンデータを設ける目的は、国民参加・官民協働の推進による諸課題の解決、経済の活性化や、透明性・信頼性の向上、地域の課題の解決などがあるということを初めて知った。これを聞いて、是非積極的にオープンデータを見て活用するべきだなと思った。\\nL11-Q3: NaN\\nL11-Q4: NaN\\nL11-Q5: 個人情報の定義とはなにか、考えたときざっくりとした回答しか浮かばす、しっかりとした定義が分からなかった。知らないままでは勝手に人の個人情報を流出させてしまったり、自分の個人情報を悪用されてしまったりしていたかもしれないので、授業で厳密な定義を学べてよかった。\\nL12-Q1: ベクトルとは複数の数値を塊にしたもので、順番に意味がある。ベクトル表現されたデータ分析には線形代数も使われる。ベクトルはデータの組み合わせなので、1つの組み合わせでは分からないことも、多数のデータを用意することで、データ間の関係が見えてくる。データ分析における距離とはデータ間の差異のことであり、類似度とは距離とは反対の概念のことである。距離は1種類ではなく、2点間の最短距離を表すユークリッド距離や斜めに行けない場合の距離を表すマンハッタン距離、Max距離、長さの同じ2系列間の距離を表すハミング距離などがある。\\nL12-Q2: データ解析に距離はとても重要で、距離が変わると、解析結果はまるきり変わるということが分かった。たくさんある距離の中から、データや解析問題の性質に合った距離を選ぶことが大事だということを知った。\\nL12-Q3: NaN\\nL12-Q4: NaN\\nL12-Q5: 距離や類似度がデータに大きな影響を及ぼすことを知らなかった。今日の授業は図を見るとすごく分かりやすかった。\\nL13-Q1: 可視化とはデータを直感的に理解できる図にすることであり、膨大なデータを把握するのを簡単にする。可視化における注意点として、不適切な可視化は誤解や不快な印象を与えることから、目的と条件によって適切なものを選択する必要がある。棒グラフとは棒の高さで値を表現した図であり、数値データの比較を行うときに有効である。ヒストグラムとは区間ごとにデータが観測された回数を集計した図であり、データの分布を調べる場合に有効である。箱ひげ図はデータ分布を最大値、最小値、四分位数で表現した図で、データ分布の比較をする場合に有効である。パイチャートは円の面積で割合を表すものであり、各データの割合を表示する図だが、立体的になると面積の大小関係が異なるように見えてしまうという罠がある。折れ線グラフとはデータ点の間を直線で結んだ図でデータ点間の変化の傾向を把握するのに有効である。無向グラフや有向グラフはデータ間の関係性、接続を把握する場合に有効である。\\nL13-Q2: 可視化にはたくさん種類があるが、適切なものを利用することが大事なんだなと分かった。データをどうしたいかを明確に決めれたら、すぐに適切な可視化の手法を使えるようになりたい。\\nL13-Q3: NaN\\nL13-Q4: NaN\\nL13-Q5: 今日の授業は終始分かりやすく簡単に理解することができた。\\nL14-Q1: NaN\\nL14-Q2: NaN\\nL14-Q3: NaN\\nL14-Q4: NaN\\nL14-Q5: NaN\\nL15-Q1: NaN\\nL15-Q2: NaN\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: NaN\\n[/INST]\\nこの学生の成績は、Cです。理由は、質問1や質問2において講義内容をある程度理解している様子が見られるものの、質問3や質問4に未回答が多く、理解が不十分な部分や質問があるにもかかわらずそれを明確にしていないためです。また、質問5の感想では理解に苦しんだという記述が複数回見られ、全体的な理解度が高くないことが示唆されます。']\n",
      "2025-06-18 15:18:55,128 : src.util : DEBUG : 21 : batch:\n",
      "{'input_ids': tensor([[128256, 128256, 128256,  ...,  33541,   1811, 128009],\n",
      "        [    58,  65562,     60,  ...,  33541,   1811, 128009]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[  -100,   -100,   -100,  ...,  33541,   1811, 128009],\n",
      "        [  -100,   -100,   -100,  ...,  33541,   1811, 128009]]), 'target_ids': tensor([[ 51330, 106718,  16144,  13153, 116486,  15682,   5486,     35,  38641,\n",
      "           1811, 114667,  15682,   5486, 105284,  99397,    868,     12,     17,\n",
      "         124001,    868,     12,     20, 121960,   5486,  23538, 106968,  57933,\n",
      "          71634, 121960,  82973,  29295, 102780,  31431, 101860,   5486,  61304,\n",
      "          43032, 109606,  29295,  30297,  17129,  47884, 102181,  76622, 104435,\n",
      "          19732,  43032, 115694, 108086,   5486,  57933,  71634, 113245,  80805,\n",
      "         108526, 108941, 107446,  29295, 103167, 102518, 103846,  38641, 118855,\n",
      "           5486, 105284,  99397,  44915,  37087,  33014,  30512,  33035,  39926,\n",
      "           5486, 113954,  29295,  16937, 114392,  26854,  23964,    229,  32938,\n",
      "          29295,  43240,  47884,   5486,  66378,  20230, 114363, 103722,  11883,\n",
      "         102158,  71289, 126067,  16144, 113954,  20230, 107202,   8239,    112,\n",
      "         103792, 103826,  45829,  29295,  91774, 101682,  76622, 102204,  33541,\n",
      "           1811, 128256, 128256, 128256, 128256, 128256],\n",
      "        [ 51330, 106718,  16144,  13153, 116486,  15682,   5486,     34,  38641,\n",
      "           1811, 114667,  15682,   5486, 105284,  99397,     16,  71289, 105284,\n",
      "          99397,     17, 121960, 114341, 104577,  44915,  30512, 101182, 113314,\n",
      "         113954, 103792, 103826,  45829,  29295,  91774, 110071, 102944,  16144,\n",
      "           5486, 105284,  99397,     18,  71289, 105284,  99397,     19,  20230,\n",
      "          39442, 113925,  29295,  43240,  47884,   5486, 113954,  29295,  16937,\n",
      "         114392,  26854, 105494,  71289, 105284,  99397, 107407, 105352,  32149,\n",
      "         124233, 121140,  77693,  30512,  31958, 105184,  20230, 109768, 100604,\n",
      "         103846,  38641, 118855,   5486, 105284,  99397,     20,  16144,  99750,\n",
      "         101067,  77181, 113954,  20230, 107202,  15024, 102189, 102677,  61304,\n",
      "          43032,  29295, 109242,   9039,  18904,  91774, 102204,   5486,  37087,\n",
      "          33014, 109904, 113954,  27479,  29295,  45736,  47884, 100604, 105908,\n",
      "          20379,  84150,    228,  84389,  33541,   1811]])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data,\n",
    "    batch_size=2,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    ")\n",
    "batch = next(iter(data_loader))\n",
    "logger.info(\n",
    "    f\"Batch keys: {batch.keys()}\"\n",
    ")  # -> Batch keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
    "for k, v in batch.items():\n",
    "    logger.info(\n",
    "        f\"Batch key: {k}, value shape: {v.shape if isinstance(v, torch.Tensor) else type(v)}\"\n",
    "    )\n",
    "# batch内のinput_idsをでコードしてプロンプトを確認\n",
    "input_text = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "logger.debug(f\"batch:\\n{batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01339275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Input prompt: \\n'\n",
      " \"['[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に \"\n",
      " 'A、B、C、D、F '\n",
      " 'のいずれかに分類してください。\\\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\\\n成績と根拠は出力例のような形式で出力してください。\\\\n入力文のL '\n",
      " 'は講義回、Q は質問番号を示します（例: '\n",
      " 'L1-Q1）。\\\\nアンケートの質問文は、\\\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\\\nQ4:質問があれば書いてください\\\\nQ5:今日の授業の感想や反省を書いてください\\\\nです。回答が '\n",
      " 'NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\\\n出力には、必ず A、B、C、D、F '\n",
      " 'のいずれかを含めてください。\\\\n出力例:\\\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\\\nアンケート内容：\\\\n\\\\nL1-Q1: '\n",
      " 'イントロダクション 情報通信方法\\\\nL1-Q2: 情報の通信の基本は昔と変わらないということがわかった\\\\nL1-Q3: NaN\\\\nL1-Q4: '\n",
      " 'NaN\\\\nL1-Q5: これからの授業が楽しみなのでしっかりと学んでいきたいです\\\\nL2-Q1: NaN\\\\nL2-Q2: NaN\\\\nL2-Q3: '\n",
      " 'NaN\\\\nL2-Q4: NaN\\\\nL2-Q5: NaN\\\\nL3-Q1: NaN\\\\nL3-Q2: NaN\\\\nL3-Q3: '\n",
      " 'NaN\\\\nL3-Q4: NaN\\\\nL3-Q5: NaN\\\\nL4-Q1: NaN\\\\nL4-Q2: NaN\\\\nL4-Q3: '\n",
      " 'NaN\\\\nL4-Q4: NaN\\\\nL4-Q5: NaN\\\\nL5-Q1: 効率のよいアルゴリズム 計算時間\\\\nL5-Q2: '\n",
      " 'アルゴリズムがなにかを把握することができた\\\\nL5-Q3: 根付き木についてがよくわからなかった\\\\nL5-Q4: NaN\\\\nL5-Q5: '\n",
      " 'プログラムとアルゴリズムについて知ることができた。最適なアルゴリズムをすぐに見つけ出せるようになりたい\\\\nL6-Q1: ユークリッドの互除法 '\n",
      " 'ソートについて\\\\nL6-Q2: ヒープソートは2進木の欠点をなくしたものである\\\\nL6-Q3: NaN\\\\nL6-Q4: NaN\\\\nL6-Q5: '\n",
      " 'ソートにはいろいろな種類があり始めて学ぶ内容だったので面白かった\\\\nL7-Q1: マージソートとはどのようなアルゴリズムか '\n",
      " '二分深索法とは\\\\nL7-Q2: 二分深索は線形深索よりも少ない比較回数ですむので圧倒的に速い\\\\nL7-Q3: '\n",
      " '比較ソートアルゴリズムの比較回数についてnlog_2nに比例して増えるということがわかりずらかった\\\\nL7-Q4: NaN\\\\nL7-Q5: '\n",
      " '最近になってシンプルな比較方法が生み出されたということにおどろいた。まだまだわかっていないだけでよりよい方法があるとおもうとわくわくした。\\\\nL8-Q1: '\n",
      " 'NaN\\\\nL8-Q2: NaN\\\\nL8-Q3: NaN\\\\nL8-Q4: NaN\\\\nL8-Q5: NaN\\\\nL9-Q1: '\n",
      " 'NaN\\\\nL9-Q2: NaN\\\\nL9-Q3: NaN\\\\nL9-Q4: NaN\\\\nL9-Q5: NaN\\\\nL10-Q1: '\n",
      " '非構造データ(文字、画像、音声など)の解析 パターン認識\\\\nL10-Q2: コンピュータにもを判別させることは難しいことがわかった\\\\nL10-Q3: '\n",
      " 'パターン認識のイメージ図がわからなかった\\\\nL10-Q4: NaN\\\\nL10-Q5: '\n",
      " '時代が進むにつれてAIが認識できる範囲も広がっていくと思うとなんだかわくわくする。\\\\nL11-Q1: 調査 個人情報 '\n",
      " 'オープンデータ\\\\nL11-Q2: 全数調査のメリット・デメリット 個人情報の保護に関して\\\\nL11-Q3: '\n",
      " 'オープンデータがどのようなものかはわかったが著作権のあたりからわからなかった\\\\nL11-Q4: NaN\\\\nL11-Q5: '\n",
      " '全数調査ができないとき、どのような基準でデータをとっているのか知らなかったが今回しれてよかった。バイアスという言葉になじみがなくわかりにくかったがなんとか理解できたと思う。\\\\nL12-Q1: '\n",
      " 'NaN\\\\nL12-Q2: NaN\\\\nL12-Q3: NaN\\\\nL12-Q4: NaN\\\\nL12-Q5: NaN\\\\nL13-Q1: '\n",
      " '可視化についてどのグラフが適しているか、また表し方によるわかりにくさなど\\\\nL13-Q2: '\n",
      " '要素を変更することによってグラフから得られるイメージを変えることができる\\\\nL13-Q3: NaN\\\\nL13-Q4: NaN\\\\nL13-Q5: '\n",
      " 'グラフは使い方によってよりわかりやすくもできるが、適していないグラフだと理解を妨げたり間違ったイメージを与えることも可能なので慎重に用いていく必要があるなと思いました。\\\\nL14-Q1: '\n",
      " '分布、分散、相関係数について統計的検定とは統計差を評価する枠組みのことである。 画像のフィルター\\\\nL14-Q2: 分布、分散の活用方法 '\n",
      " '画像の処理方法の種類\\\\nL14-Q3: 統計的検定の有意水準などの言葉の意味がわかりずらかった\\\\nL14-Q4: NaN\\\\nL14-Q5: '\n",
      " '分布などはこれから多く見かけたり用いていくことになると思うので、しっかりと身につけておきたいです。有意水準や帰無仮説などややこしい用語が多く出て理解しずらかったがテストに向けて頑張っていきたいと思う。\\\\nL15-Q1: '\n",
      " '画像のエッジに関して テスト\\\\nL15-Q2: '\n",
      " '期末テストに準備して挑んだつもりだったが全く時間が足りず努力が足りなかったと痛感した。\\\\nL15-Q3: NaN\\\\nL15-Q4: '\n",
      " 'NaN\\\\nL15-Q5: '\n",
      " \"記述問題があまりうまくかけなかったので授業で習ったことを自分の言葉で言い表せるようになることが必要だと思いました。大学に入って初めてのテストでしたが力を発揮できなかったのでこれからのテストをもっと頑張ろうと思いました。\\\\n[/INST]\\\\nこの学生の成績は、Dです。理由は、質問15-2および15-5において、期末テストにおいて時間が足りず、記述問題がうまく書けなかったと述べており、テストでのパフォーマンスが低かったためです。また、質問内容全体を通して、理解が不十分な箇所が多く、特に専門用語や概念の理解に苦労している様子が見受けられます。', \"\n",
      " \"'[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に \"\n",
      " 'A、B、C、D、F '\n",
      " 'のいずれかに分類してください。\\\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\\\n成績と根拠は出力例のような形式で出力してください。\\\\n入力文のL '\n",
      " 'は講義回、Q は質問番号を示します（例: '\n",
      " 'L1-Q1）。\\\\nアンケートの質問文は、\\\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\\\nQ4:質問があれば書いてください\\\\nQ5:今日の授業の感想や反省を書いてください\\\\nです。回答が '\n",
      " 'NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\\\n出力には、必ず A、B、C、D、F '\n",
      " 'のいずれかを含めてください。\\\\n出力例:\\\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\\\nアンケート内容：\\\\n\\\\nL1-Q1: '\n",
      " '遠くに情報を伝える方法として、初めは狼煙やたいこなどで合図を送るという手段が使われていたが、文字を発明して文章を送ったり、モールス信号を発明したりすることで伝達手段を増やしていった。\\\\nL1-Q2: '\n",
      " 'モールス信号を学ぶ楽しさを知ることができた。\\\\nL1-Q3: NaN\\\\nL1-Q4: NaN\\\\nL1-Q5: '\n",
      " 'モールス信号についてもっと知りたいと思った。\\\\nL2-Q1: NaN\\\\nL2-Q2: NaN\\\\nL2-Q3: NaN\\\\nL2-Q4: '\n",
      " 'NaN\\\\nL2-Q5: NaN\\\\nL3-Q1: '\n",
      " '情報量が増えれば増えるほどその事象の曖昧さは減少する。また、滅多に起きない事象の生起を知ることで得られる情報量は大きい。\\\\nL3-Q2: '\n",
      " '今回の授業における猫の機嫌と尻尾の関係の例を聞いて相互情報量について理解を深めることができた。\\\\nL3-Q3: NaN\\\\nL3-Q4: '\n",
      " 'NaN\\\\nL3-Q5: '\n",
      " '今回は数学的な考え方をすることが多くて理解を深めるのに苦しんだが、例題を解いたり、説明を聞いたりすることで理解することができた。\\\\nL4-Q1: '\n",
      " '通信路を通してビット列を伝送する際、ノイズの影響によりビットの反転が起きる場合がある。この反転の対策として送信電力を大きくし信号対雑音電力比を向上させる、大型のアンテナを使い受信信号電力を向上させる、受信アンプを冷却し受信器内の熱雑音を減少させる、より広い周波数帯域を利用するなどがあるが、物理的、経済的制限によりこれらの方策が取れないことが多い。なのでもう一つの対策として符号化を工夫するというのがある。これは自動誤り検出と自動誤り訂正でビット反転があったことを検出し再送、訂正するというものだ。\\\\nL4-Q2: '\n",
      " 'ビット列を送信する際、通信路を通して伝送するときにノイズの影響でビットの反転が起きることがあるとわかった。\\\\nL4-Q3: NaN\\\\nL4-Q4: '\n",
      " 'NaN\\\\nL4-Q5: 今日の授業は難しいところが多く理解に苦しんだ。\\\\nL5-Q1: '\n",
      " '計算には物理的アプローチとCS的アプローチがある。物理的アプローチは観測に基づいて現象を法律化するもので法律が正しいということは決して証明できないため、反例が発見されると法律は棄却されてしまう。CS的アプローチはあらゆる問題を関数の計算問題として形式化するもので、問題を解くための効率の良い計算手順を設計する。計算手順の正当性や効率化の限界は証明できる。 '\n",
      " 'コンピュータが行なっていることは全て計算である。計算をうまく制御するために計算がどのようなものであるかを理解する科学がコンピュータサイエンスである。コンピュータの計算は単純な計算を組み合わせることで実現する。この組み合わせ方をアルゴリズムといい、計算の手順である。\\\\nL5-Q2: '\n",
      " '偽コインを発見する問題で、9枚のコインの中から偽のコインを見つけるというもので2回天秤にかけるだけで見つけ出すことができるというやり方を自分で思いつくことができなかったので驚いた。\\\\nL5-Q3: '\n",
      " 'NaN\\\\nL5-Q4: NaN\\\\nL5-Q5: '\n",
      " '自分は普段何気なくコンピュータを使っているが、コンピュータの計算について知ろうと思ったり、深く考えてみたことがなかった。今後はコンピュータサイエンスの観点から計算をうまく扱えるようになりたい。\\\\nL6-Q1: '\n",
      " '計算ステップ数とはアルゴリズムが終了するまでに行われる基本演算の回数のことで、計算ステップ数が少ないほどアルゴリズムの実行時間は短くなる。 '\n",
      " 'n個のアイテムが与えられたときそれらをある順序によって並び替えることをソートという。ソートは計算機科学における最も基本的な問題の一つである。隣り合う要素の大小を比較しながら整列していくバブルソートや、最大の要素を探し、それと最後の要素を入れ替える選択ソートなどがある。\\\\nL6-Q2: '\n",
      " '要素の比較回数、最大値の更新回数、要素の更新回数で時間計算量を見積もることができるとわかった。\\\\nL6-Q3: NaN\\\\nL6-Q4: '\n",
      " 'NaN\\\\nL6-Q5: オーダー記法が難しくあまり理解できなかった。\\\\nL7-Q1: '\n",
      " 'ソート問題の解法の一つとして、各節点が高々二つの子しか持たない根付き木のことである二進木がある。二進木の読み方は節点の値を左、自分、右の順に読む。二進木を使ったソートの欠点は入力数列の並び方で計算時間が変わるということだ。節点数n、高さhの二進木が、・深さdの節点がちょうど2^d個存在し、深さhの節点は左から順に存在する。・どの節点も自分の親に格納された値以下である。という二つの条件を満たすときその木をヒープという。\\\\nL7-Q2: '\n",
      " '二進木を使用しない方がシンプルで見やすいことが分かった。ソートアルゴリズムは必ずO(nlogn)回の比較を要すると分かった。\\\\nL7-Q3: '\n",
      " 'NaN\\\\nL7-Q4: NaN\\\\nL7-Q5: 二進木がすごく複雑で分かりにくかった\\\\nL8-Q1: '\n",
      " '線形探索は左端からxを探していくので最悪の場合n回の要素比較をしなければならない。2分探索は真ん中の要素yとxを比較する。なので各ステップで探索する範囲は必ず1/2以下になる。つまり線形探索よりも2分探索の方が速い。\\\\nL8-Q2: '\n",
      " '自分は普段から何気なくデータという単語を使っていたが、データとは何を指すかとか考えたことがなかった。授業を聞いてコンピュータ処理の対象となる記号化数字化された資料、物事の推論の基礎となる事実、情報のことであるということが分かった。\\\\nL8-Q3: '\n",
      " 'NaN\\\\nL8-Q4: NaN\\\\nL8-Q5: '\n",
      " 'データについてあまり考えたことがなかったのでデータについて学べるのがとても楽しい。また今まで数字や記号が多く出てきていて難しいなと思っていたので、今回の後半のようにわかりやすい授業は意欲が湧く。\\\\nL9-Q1: '\n",
      " 'データ分析の基本として予測、傾向や関連の発見、分類・グルーピングがある。予測とは過去のデータの傾向や結果に基づいてデータの予想を立てることである。予測は過去のデータを集められなかったり、要因が不明な場合があったり、現時点と予測時点で状況が違う場合があったりすることから難しい時もある。発見とは相関分析や頻出パターンを使ってデータを分析することである。分類・グルーピングとはデータをいくつかのグループに分けることでデータの把握を容易にするものである。 '\n",
      " '人工知能とは人間の知能を真似する機械のことであり、大きく特化型AIと汎用AIに分かれる。特化型AIは特定の知能だけを学習したAIのことである。また、汎用AIとは人間の知能と同じ柔軟さと多機能性を持つAIのことである。ただ、まだ実現はしていないのが現状である。\\\\nL9-Q2: '\n",
      " 'AIを活用することでビジネスもできることが分かった。人工知能をうまく活用できるようになれば、ビジネスを成功させるだけでなく、仕事を奪われることもないと分かった。\\\\nL9-Q3: '\n",
      " 'NaN\\\\nL9-Q4: NaN\\\\nL9-Q5: '\n",
      " '最近はAIが当たり前に身の回りにあるようになってきているが、それらのAIは人間以上の知能を持ちうるだけに、うまく活用しなければ色々なことを奪われてしまうことが分かった。\\\\nL10-Q1: '\n",
      " '非構造データとは文章や画像、音がその代表例で、表形式にはならないため非構造化データと呼ばれる。非構造データ処理には言語処理や画像処理、音声音楽処理などがある。パターン認識とはさまざまなデータを対象としてそれが何であるかをコンピュータに解かせるというものだ。人間は画像の認識や音声の認識を無意識、高精度に実現可能であるが、コンピュータに理解させるのは難しい。\\\\nL10-Q2: '\n",
      " '人間にとっては画像や音声を認識することはなんちゃないことで簡単だと思っていたが、コンピュータにとってはとても難しいことであるということが分かった。また、それでも最近はパターン認識が身近になっていることは技術の発展に驚いた。\\\\nL10-Q3: '\n",
      " 'NaN\\\\nL10-Q4: NaN\\\\nL10-Q5: '\n",
      " '人間にできることでコンピュータにできないことはもうないんじゃないかと思うほどコンピュータにできることが増えていてこれからの未来が楽しみである。\\\\nL11-Q1: '\n",
      " '正確なデータに基づいて調査するために、データを集める方法として、調査対象を全て調べる全数調査が理想として挙げられる。ただし、全数調査を使える場面は、すべての母集団を調査できる環境が整っている、母集団の規模が小さいときなどに限られる。そのため、一般的に全数調査は不可能であると考えられている。メリットとしては真実のデータがとれる。全数調査が無理な場合、母集団の一部を取り出して調査する標本調査があげられる。標本調査は偏りが生まれる可能性がある。偏りが入らないようにデータを収集するために、ランダムにデータを選べばよい。 '\n",
      " '個人情報保護法による個人情報の定義とは、生存する個人に関する情報であって、氏名ら生年月日等特定の個人を識別することができるもの、個人識別符号が含まれるもののことである。オープンデータとは市民や企業が使いやすい公共データのことである。ただし、ホームページで公開しているものがオープンデータというわけではない。\\\\nL11-Q2: '\n",
      " 'オープンデータを設ける目的は、国民参加・官民協働の推進による諸課題の解決、経済の活性化や、透明性・信頼性の向上、地域の課題の解決などがあるということを初めて知った。これを聞いて、是非積極的にオープンデータを見て活用するべきだなと思った。\\\\nL11-Q3: '\n",
      " 'NaN\\\\nL11-Q4: NaN\\\\nL11-Q5: '\n",
      " '個人情報の定義とはなにか、考えたときざっくりとした回答しか浮かばす、しっかりとした定義が分からなかった。知らないままでは勝手に人の個人情報を流出させてしまったり、自分の個人情報を悪用されてしまったりしていたかもしれないので、授業で厳密な定義を学べてよかった。\\\\nL12-Q1: '\n",
      " 'ベクトルとは複数の数値を塊にしたもので、順番に意味がある。ベクトル表現されたデータ分析には線形代数も使われる。ベクトルはデータの組み合わせなので、1つの組み合わせでは分からないことも、多数のデータを用意することで、データ間の関係が見えてくる。データ分析における距離とはデータ間の差異のことであり、類似度とは距離とは反対の概念のことである。距離は1種類ではなく、2点間の最短距離を表すユークリッド距離や斜めに行けない場合の距離を表すマンハッタン距離、Max距離、長さの同じ2系列間の距離を表すハミング距離などがある。\\\\nL12-Q2: '\n",
      " 'データ解析に距離はとても重要で、距離が変わると、解析結果はまるきり変わるということが分かった。たくさんある距離の中から、データや解析問題の性質に合った距離を選ぶことが大事だということを知った。\\\\nL12-Q3: '\n",
      " 'NaN\\\\nL12-Q4: NaN\\\\nL12-Q5: '\n",
      " '距離や類似度がデータに大きな影響を及ぼすことを知らなかった。今日の授業は図を見るとすごく分かりやすかった。\\\\nL13-Q1: '\n",
      " '可視化とはデータを直感的に理解できる図にすることであり、膨大なデータを把握するのを簡単にする。可視化における注意点として、不適切な可視化は誤解や不快な印象を与えることから、目的と条件によって適切なものを選択する必要がある。棒グラフとは棒の高さで値を表現した図であり、数値データの比較を行うときに有効である。ヒストグラムとは区間ごとにデータが観測された回数を集計した図であり、データの分布を調べる場合に有効である。箱ひげ図はデータ分布を最大値、最小値、四分位数で表現した図で、データ分布の比較をする場合に有効である。パイチャートは円の面積で割合を表すものであり、各データの割合を表示する図だが、立体的になると面積の大小関係が異なるように見えてしまうという罠がある。折れ線グラフとはデータ点の間を直線で結んだ図でデータ点間の変化の傾向を把握するのに有効である。無向グラフや有向グラフはデータ間の関係性、接続を把握する場合に有効である。\\\\nL13-Q2: '\n",
      " '可視化にはたくさん種類があるが、適切なものを利用することが大事なんだなと分かった。データをどうしたいかを明確に決めれたら、すぐに適切な可視化の手法を使えるようになりたい。\\\\nL13-Q3: '\n",
      " 'NaN\\\\nL13-Q4: NaN\\\\nL13-Q5: 今日の授業は終始分かりやすく簡単に理解することができた。\\\\nL14-Q1: '\n",
      " 'NaN\\\\nL14-Q2: NaN\\\\nL14-Q3: NaN\\\\nL14-Q4: NaN\\\\nL14-Q5: NaN\\\\nL15-Q1: '\n",
      " 'NaN\\\\nL15-Q2: NaN\\\\nL15-Q3: NaN\\\\nL15-Q4: NaN\\\\nL15-Q5: '\n",
      " \"NaN\\\\n[/INST]\\\\nこの学生の成績は、Cです。理由は、質問1や質問2において講義内容をある程度理解している様子が見られるものの、質問3や質問4に未回答が多く、理解が不十分な部分や質問があるにもかかわらずそれを明確にしていないためです。また、質問5の感想では理解に苦しんだという記述が複数回見られ、全体的な理解度が高くないことが示唆されます。']\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(f\"Input prompt: \\n{input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc608ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
