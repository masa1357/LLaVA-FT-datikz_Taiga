{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e967348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421ea8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be05292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.gradeexplanation_data import GradeExplanationDataset, GradeExplanationCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cd6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elyza/Llama-3-ELYZA-JP-8B tokenizerのロード\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"elyza/Llama-3-ELYZA-JP-8B\")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "#! pad_token が無い場合だけ追加\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "#! 語彙サイズを合わせる\n",
    "# model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc9515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.gradeexplanation_data' from '/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import src\n",
    "\n",
    "importlib.reload(src.gradeexplanation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81892d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path.cwd().parent\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "data = GradeExplanationDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b174f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5081305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史',\n",
       "  'Q2': '情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'フランスの腕木通信は知らなかったのでおもしろいと思いました。'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号',\n",
       "  'Q2': '符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。',\n",
       "  'Q3': '最適符号の定義',\n",
       "  'Q4': '平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。',\n",
       "  'Q5': '前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量',\n",
       "  'Q2': '情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい',\n",
       "  'Q3': '曖昧さ=log の証明',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'エントロピーがまだよくわかっていないので、しっかり復習したいです'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量',\n",
       "  'Q2': '誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、',\n",
       "  'Q3': '通信路符号化定理、検査ビット',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム',\n",
       "  'Q2': 'アルゴリズムの定義について',\n",
       "  'Q3': '根付き木がまだよく分からなかった。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート',\n",
       "  'Q2': 'それぞれのソートのやり方',\n",
       "  'Q3': 'ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索',\n",
       "  'Q2': 'マージソートのやり方、二分探索のアルゴリズム',\n",
       "  'Q3': 'キーワードの二分探索がちょっと微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '線形探索と比べて、二分探索の計算量の少なさに驚きました。'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング',\n",
       "  'Q2': 'データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方',\n",
       "  'Q3': '特にないです',\n",
       "  'Q4': '特にないです',\n",
       "  'Q5': 'データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと',\n",
       "  'Q2': '人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細',\n",
       "  'Q3': 'オープン戦略のあたりがまだ曖昧です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用',\n",
       "  'Q2': '非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用',\n",
       "  'Q3': 'とくにないです',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権',\n",
       "  'Q2': 'データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方',\n",
       "  'Q3': 'オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用',\n",
       "  'Q2': 'ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用',\n",
       "  'Q3': 'max距離の使い方とコサイン類似度が微妙です',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方',\n",
       "  'Q2': '棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点',\n",
       "  'Q3': '多次元データの可視化',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': 'パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出',\n",
       "  'Q2': '相関係数の求め方、相関や分散や統計的検定の特徴',\n",
       "  'Q3': '微分フィルタ、ソーベルフィルタ',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト',\n",
       "  'Q2': 'ラプラシアンフィルタについて',\n",
       "  'Q3': 'NaN',\n",
       "  'Q4': 'NaN',\n",
       "  'Q5': '期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。'},\n",
       " 'input_text': 'L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\\nL1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\\nL1-Q3: 特にないです\\nL1-Q4: NaN\\nL1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\\nL2-Q1: 情報源とその符号化、望ましい符号\\nL2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\\nL2-Q3: 最適符号の定義\\nL2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\\nL2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\\nL3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\\nL3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\\nL3-Q3: 曖昧さ=log の証明\\nL3-Q4: 特にないです\\nL3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\\nL4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\\nL4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\\nL4-Q3: 通信路符号化定理、検査ビット\\nL4-Q4: NaN\\nL4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\\nL5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\\nL5-Q2: アルゴリズムの定義について\\nL5-Q3: 根付き木がまだよく分からなかった。\\nL5-Q4: NaN\\nL5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\\nL6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\\nL6-Q2: それぞれのソートのやり方\\nL6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\\nL6-Q4: NaN\\nL6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\\nL7-Q1: マージソート、二分探索\\nL7-Q2: マージソートのやり方、二分探索のアルゴリズム\\nL7-Q3: キーワードの二分探索がちょっと微妙です\\nL7-Q4: NaN\\nL7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\\nL8-Q1: データとは、データの種類、予測、発見、グルーピング\\nL8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\\nL8-Q3: 特にないです\\nL8-Q4: 特にないです\\nL8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\\nL9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\\nL9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\\nL9-Q3: オープン戦略のあたりがまだ曖昧です\\nL9-Q4: NaN\\nL9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\\nL10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\\nL10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\\nL10-Q3: とくにないです\\nL10-Q4: NaN\\nL10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\\nL11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\\nL11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\\nL11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\\nL11-Q4: NaN\\nL11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\\nL12-Q1: ベクトル、距離、類似度、それらの種類や応用\\nL12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\\nL12-Q3: max距離の使い方とコサイン類似度が微妙です\\nL12-Q4: NaN\\nL12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\\nL13-Q1: データの可視化、そのいろいろなやり方\\nL13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\\nL13-Q3: 多次元データの可視化\\nL13-Q4: NaN\\nL13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\\nL14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\\nL14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\\nL14-Q3: 微分フィルタ、ソーベルフィルタ\\nL14-Q4: NaN\\nL14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\\nL15-Q1: 画像処理の補足、期末テスト\\nL15-Q2: ラプラシアンフィルタについて\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 31\n",
    "data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d106c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_data = GradeExplanationDataset(\n",
    "    dataset_path=DATA_PATH,\n",
    "    question_filter=[1],\n",
    "    tokenizer=tokenizer,\n",
    "    max_tokens=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d488c611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userid': 'C-2021-1_U30',\n",
       " 'labels': 0,\n",
       " 'grades': 'A',\n",
       " 'L1': {'Q1': '情報イントロダクション、情報の大まかな仕組み、情報の歴史'},\n",
       " 'L2': {'Q1': '情報源とその符号化、望ましい符号'},\n",
       " 'L3': {'Q1': '情報量、曖昧さの減少、情報の期待値、相互情報量'},\n",
       " 'L4': {'Q1': 'ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量'},\n",
       " 'L5': {'Q1': 'コンピューターサイエンスとは、計算、アルゴリズム'},\n",
       " 'L6': {'Q1': 'バブルソート、選択ソート、2進木ソート、ヒープソート'},\n",
       " 'L7': {'Q1': 'マージソート、二分探索'},\n",
       " 'L8': {'Q1': 'データとは、データの種類、予測、発見、グルーピング'},\n",
       " 'L9': {'Q1': '人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと'},\n",
       " 'L10': {'Q1': '非構造データ(言語、画像、音声)、パターン認識とその応用'},\n",
       " 'L11': {'Q1': 'データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権'},\n",
       " 'L12': {'Q1': 'ベクトル、距離、類似度、それらの種類や応用'},\n",
       " 'L13': {'Q1': 'データの可視化、そのいろいろなやり方'},\n",
       " 'L14': {'Q1': '相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出'},\n",
       " 'L15': {'Q1': '画像処理の補足、期末テスト'},\n",
       " 'input_text': 'L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\\nL2-Q1: 情報源とその符号化、望ましい符号\\nL3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\\nL4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\\nL5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\\nL6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\\nL7-Q1: マージソート、二分探索\\nL8-Q1: データとは、データの種類、予測、発見、グルーピング\\nL9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\\nL10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\\nL11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\\nL12-Q1: ベクトル、距離、類似度、それらの種類や応用\\nL13-Q1: データの可視化、そのいろいろなやり方\\nL14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\\nL15-Q1: 画像処理の補足、期末テスト'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_data.__len__()\n",
    "Q1_data.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7ed454",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Q1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42557042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\n",
      "L1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\n",
      "L1-Q3: 特にないです\n",
      "L1-Q4: NaN\n",
      "L1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\n",
      "L2-Q1: 情報源とその符号化、望ましい符号\n",
      "L2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\n",
      "L2-Q3: 最適符号の定義\n",
      "L2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\n",
      "L2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\n",
      "L3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\n",
      "L3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\n",
      "L3-Q3: 曖昧さ=log の証明\n",
      "L3-Q4: 特にないです\n",
      "L3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\n",
      "L4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\n",
      "L4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\n",
      "L4-Q3: 通信路符号化定理、検査ビット\n",
      "L4-Q4: NaN\n",
      "L4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\n",
      "L5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\n",
      "L5-Q2: アルゴリズムの定義について\n",
      "L5-Q3: 根付き木がまだよく分からなかった。\n",
      "L5-Q4: NaN\n",
      "L5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\n",
      "L6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\n",
      "L6-Q2: それぞれのソートのやり方\n",
      "L6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\n",
      "L6-Q4: NaN\n",
      "L6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\n",
      "L7-Q1: マージソート、二分探索\n",
      "L7-Q2: マージソートのやり方、二分探索のアルゴリズム\n",
      "L7-Q3: キーワードの二分探索がちょっと微妙です\n",
      "L7-Q4: NaN\n",
      "L7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\n",
      "L8-Q1: データとは、データの種類、予測、発見、グルーピング\n",
      "L8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\n",
      "L8-Q3: 特にないです\n",
      "L8-Q4: 特にないです\n",
      "L8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\n",
      "L9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\n",
      "L9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\n",
      "L9-Q3: オープン戦略のあたりがまだ曖昧です\n",
      "L9-Q4: NaN\n",
      "L9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\n",
      "L10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\n",
      "L10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\n",
      "L10-Q3: とくにないです\n",
      "L10-Q4: NaN\n",
      "L10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\n",
      "L11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\n",
      "L11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\n",
      "L11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\n",
      "L11-Q4: NaN\n",
      "L11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\n",
      "L12-Q1: ベクトル、距離、類似度、それらの種類や応用\n",
      "L12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\n",
      "L12-Q3: max距離の使い方とコサイン類似度が微妙です\n",
      "L12-Q4: NaN\n",
      "L12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\n",
      "L13-Q1: データの可視化、そのいろいろなやり方\n",
      "L13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\n",
      "L13-Q3: 多次元データの可視化\n",
      "L13-Q4: NaN\n",
      "L13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\n",
      "L14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\n",
      "L14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\n",
      "L14-Q3: 微分フィルタ、ソーベルフィルタ\n",
      "L14-Q4: NaN\n",
      "L14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\n",
      "L15-Q1: 画像処理の補足、期末テスト\n",
      "L15-Q2: ラプラシアンフィルタについて\n",
      "L15-Q3: NaN\n",
      "L15-Q4: NaN\n",
      "L15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。\n",
      "\n",
      " input_text length: 1995\n"
     ]
    }
   ],
   "source": [
    "# data内のinputtextを確認\n",
    "print(data.__getitem__(idx)[\"input_text\"])\n",
    "print(\n",
    "    f\"\\n input_text length: {len(tokenizer.encode(data.__getitem__(idx)['input_text']))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b5ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_dataset keys: ['userid', 'labels', 'grades', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10', 'L11', 'L12', 'L13', 'L14', 'L15', 'input_text', 'target']\n",
      "Sample: {'userid': 'C-2021-1_U1', 'labels': 4, 'grades': 'F', 'L1': {'Q1': '情報伝達には声、モールス信号など様々な形があり、人類の進化と共により高度に精度が高められてきた。', 'Q2': '0と1が情報伝達において使われるということは高校の情報でも学んだことですが、この授業でより深く多面的に学ぶことができました。', 'Q3': '電子教科書を使うのが久しぶりだったので、戸惑う場面がありました。', 'Q4': 'NaN', 'Q5': '授業中に使用されているスライドが簡潔で理解しやすいです。次はもっと電子教科書を使いこなせるようにしたいです。'}, 'L2': {'Q1': '情報源符号化とは、情報を黒と白の○で表すことで、複合とは符号化によって得られたものを元に戻す作業のことである。それらの過程の中で、平均符号語長を短くすることが目指される。そこで一意符号可能性と瞬時復号可能性を持つ語頭符号を用いる。 エントロピーとは平均符号語長の下限のことである。', 'Q2': '確率やlogなど高校時代に学習した数学の知識が出てきたが、ぎりぎり思い出しながら授業を受けることができた。', 'Q3': '情報源符号化定理で、Sの最適符号C*の平均符号語長がエントロピーとエントロピー+1の値の間に収まるのかがあまりよく分からなかったです。', 'Q4': 'NaN', 'Q5': '今日の内容は文系の私でもぎりぎり理解できました。今日の内容を忘れないうちに演習問題に取り組んで知識を定着させておこうと思います。'}, 'L3': {'Q1': '生起確率pの事象の生起を知ったことによる曖昧さの減少量は情報量と一致し、生起確率pが高いほど情報量は現状しまた逆もしかりである。またエントロピーは情報量の期待値と一致する。相互情報量とは、ある事象2つが相互に関連して生起した場合に得られる情報量のことである。', 'Q2': 'エントロピーは情報量と曖昧さの減少量に関連する。PrはPriorityで確率を示すものである。|は条件付き確率を示すときに使われる。', 'Q3': '相互情報量の求め方をまだ理解していないので復習する。', 'Q4': 'NaN', 'Q5': '予習するときはスライドを見るだけでなく演習問題にも取り組んでおこうと思った。今回予習はしていったが、演習問題は解かなかった。しかし、大学受験から2年以上経ち数学の知識がほとんど抜けた今の状態では全く追いつけないので先に演習問題にも取り組んでおかなければならないと痛感した。'}, 'L4': {'Q1': '通信の際に符号の誤りを検出・訂正する仕組みについて学んだ。符号の誤りは、符号語同士がs+1以上離れていればs個検出でき、2t+1離れていればt個訂正することができる。また、その距離をハミング距離と言う。', 'Q2': 'ハミング距離は符号同士の異なっている点の数のことだと理解した。', 'Q3': '特にないです。', 'Q4': 'LGCへの投稿を情報科学の欄にしたのですが、他の投稿がやっている授業内容と違っていて、自分がきちんと投稿できているのか不安です。', 'Q5': '定理を理解するのが難しいと感じたので、とりあえず定理を理解する前にそういうものだと思い、あとからじっくり理解するようにしようと思った。'}, 'L5': {'Q1': 'コンピューターサイエンスは計算機科学であるともされ、全ての科学技術分野の基盤となりうるものである。コンピューター上で行われている全てのことは「計算」であり、コンピューターサイエンスはそれを制御・理解するための科学である。 アルゴリズムとは、関数の計算方法を示す手続きのことを言い、プログラムとはアルゴリズムをコンピューターが分かる言葉で記述したものである。アルゴリズムを上手く考えることができれば、「偽コイン発見」の問題のように作業を効率化・最適化することができる。大きな数の因数分解は難しいため、ユークリッドの互除法を用いれば容易に計算できる。', 'Q2': 'アルゴリズムとプログラムの違いはなんであるか前々から疑問であったが、今回の授業で両者の違いと関連性についてはっきり理解することができた。', 'Q3': 'やはり、計算や数学の知識が必要になる点になると途端に理解が追いつかなくなってしまう。', 'Q4': 'NaN', 'Q5': '次回はより時間をかけて予習をしてから授業に臨みたいと思う。'}, 'L6': {'Q1': '計算ステップ数とは、アルゴリズムが終了するまでに行われる演算の数である。最大公約数の問題では剰余を考える。バブルソートとは、隣り合う要素の大小を比較しながら昇順もしくは降順に整列していくことである。2進木のソートを読むときには通りがけ順で、左の子→自分→右の子、の順番で読む。2進木の一種にヒープがある。', 'Q2': 'バブルソートは高校の授業で知っていたが、他のソートは知らなかった。今回は授業の内容の大体を把握することができたと思う。', 'Q3': 'なぜこういったソートの種類が複数あるのかが分からないので、これから課題に取り組む内に見つけようと思う。', 'Q4': 'NaN', 'Q5': '今回の授業は大体を理解できたが、分かっていないところが少しあるのでしっかりと復習する。また、来週はより丁寧に予習をしてから、授業に臨もうと思う。'}, 'L7': {'Q1': 'マージソートとは、入力数列を分割していき、分割したものを整列して統合(マージ)するアルゴリズムである。ヒープソートと同様にO(nlogn)回の比較で要素を整列する。2進木を使用しないためよりシンプルである。最悪時の比較回数は決定木の高さに等しい。 線形探索が数列を先頭から探索していくのに対し、二部探索は真ん中の要素から比較して前半部分・後半部分のどちらか選んで探索していくものである。なので、後者の方が圧倒的に速い。', 'Q2': 'ヒープソートと二部探索はだいたいの仕組みを理解することができた。計算も、考えてみればよく分かるものが多く、復習すればより定着させることが出来ると思う。', 'Q3': 'テキストの二部探索がよくわからなかった。接尾辞からどう探索していくのかがいまいち分かっていない。', 'Q4': 'NaN', 'Q5': 'LGCに記事を載せられるほどまだ理解していないので、すぐに復習するようにします。'}, 'L8': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L9': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L10': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L11': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L12': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L13': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L14': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'L15': {'Q1': 'NaN', 'Q2': 'NaN', 'Q3': 'NaN', 'Q4': 'NaN', 'Q5': 'NaN'}, 'input_text': 'L1-Q1: 情報伝達には声、モールス信号など様々な形があり、人類の進化と共により高度に精度が高められてきた。\\nL1-Q2: 0と1が情報伝達において使われるということは高校の情報でも学んだことですが、この授業でより深く多面的に学ぶことができました。\\nL1-Q3: 電子教科書を使うのが久しぶりだったので、戸惑う場面がありました。\\nL1-Q4: NaN\\nL1-Q5: 授業中に使用されているスライドが簡潔で理解しやすいです。次はもっと電子教科書を使いこなせるようにしたいです。\\nL2-Q1: 情報源符号化とは、情報を黒と白の○で表すことで、複合とは符号化によって得られたものを元に戻す作業のことである。それらの過程の中で、平均符号語長を短くすることが目指される。そこで一意符号可能性と瞬時復号可能性を持つ語頭符号を用いる。 エントロピーとは平均符号語長の下限のことである。\\nL2-Q2: 確率やlogなど高校時代に学習した数学の知識が出てきたが、ぎりぎり思い出しながら授業を受けることができた。\\nL2-Q3: 情報源符号化定理で、Sの最適符号C*の平均符号語長がエントロピーとエントロピー+1の値の間に収まるのかがあまりよく分からなかったです。\\nL2-Q4: NaN\\nL2-Q5: 今日の内容は文系の私でもぎりぎり理解できました。今日の内容を忘れないうちに演習問題に取り組んで知識を定着させておこうと思います。\\nL3-Q1: 生起確率pの事象の生起を知ったことによる曖昧さの減少量は情報量と一致し、生起確率pが高いほど情報量は現状しまた逆もしかりである。またエントロピーは情報量の期待値と一致する。相互情報量とは、ある事象2つが相互に関連して生起した場合に得られる情報量のことである。\\nL3-Q2: エントロピーは情報量と曖昧さの減少量に関連する。PrはPriorityで確率を示すものである。|は条件付き確率を示すときに使われる。\\nL3-Q3: 相互情報量の求め方をまだ理解していないので復習する。\\nL3-Q4: NaN\\nL3-Q5: 予習するときはスライドを見るだけでなく演習問題にも取り組んでおこうと思った。今回予習はしていったが、演習問題は解かなかった。しかし、大学受験から2年以上経ち数学の知識がほとんど抜けた今の状態では全く追いつけないので先に演習問題にも取り組んでおかなければならないと痛感した。\\nL4-Q1: 通信の際に符号の誤りを検出・訂正する仕組みについて学んだ。符号の誤りは、符号語同士がs+1以上離れていればs個検出でき、2t+1離れていればt個訂正することができる。また、その距離をハミング距離と言う。\\nL4-Q2: ハミング距離は符号同士の異なっている点の数のことだと理解した。\\nL4-Q3: 特にないです。\\nL4-Q4: LGCへの投稿を情報科学の欄にしたのですが、他の投稿がやっている授業内容と違っていて、自分がきちんと投稿できているのか不安です。\\nL4-Q5: 定理を理解するのが難しいと感じたので、とりあえず定理を理解する前にそういうものだと思い、あとからじっくり理解するようにしようと思った。\\nL5-Q1: コンピューターサイエンスは計算機科学であるともされ、全ての科学技術分野の基盤となりうるものである。コンピューター上で行われている全てのことは「計算」であり、コンピューターサイエンスはそれを制御・理解するための科学である。 アルゴリズムとは、関数の計算方法を示す手続きのことを言い、プログラムとはアルゴリズムをコンピューターが分かる言葉で記述したものである。アルゴリズムを上手く考えることができれば、「偽コイン発見」の問題のように作業を効率化・最適化することができる。大きな数の因数分解は難しいため、ユークリッドの互除法を用いれば容易に計算できる。\\nL5-Q2: アルゴリズムとプログラムの違いはなんであるか前々から疑問であったが、今回の授業で両者の違いと関連性についてはっきり理解することができた。\\nL5-Q3: やはり、計算や数学の知識が必要になる点になると途端に理解が追いつかなくなってしまう。\\nL5-Q4: NaN\\nL5-Q5: 次回はより時間をかけて予習をしてから授業に臨みたいと思う。\\nL6-Q1: 計算ステップ数とは、アルゴリズムが終了するまでに行われる演算の数である。最大公約数の問題では剰余を考える。バブルソートとは、隣り合う要素の大小を比較しながら昇順もしくは降順に整列していくことである。2進木のソートを読むときには通りがけ順で、左の子→自分→右の子、の順番で読む。2進木の一種にヒープがある。\\nL6-Q2: バブルソートは高校の授業で知っていたが、他のソートは知らなかった。今回は授業の内容の大体を把握することができたと思う。\\nL6-Q3: なぜこういったソートの種類が複数あるのかが分からないので、これから課題に取り組む内に見つけようと思う。\\nL6-Q4: NaN\\nL6-Q5: 今回の授業は大体を理解できたが、分かっていないところが少しあるのでしっかりと復習する。また、来週はより丁寧に予習をしてから、授業に臨もうと思う。\\nL7-Q1: マージソートとは、入力数列を分割していき、分割したものを整列して統合(マージ)するアルゴリズムである。ヒープソートと同様にO(nlogn)回の比較で要素を整列する。2進木を使用しないためよりシンプルである。最悪時の比較回数は決定木の高さに等しい。 線形探索が数列を先頭から探索していくのに対し、二部探索は真ん中の要素から比較して前半部分・後半部分のどちらか選んで探索していくものである。なので、後者の方が圧倒的に速い。\\nL7-Q2: ヒープソートと二部探索はだいたいの仕組みを理解することができた。計算も、考えてみればよく分かるものが多く、復習すればより定着させることが出来ると思う。\\nL7-Q3: テキストの二部探索がよくわからなかった。接尾辞からどう探索していくのかがいまいち分かっていない。\\nL7-Q4: NaN\\nL7-Q5: LGCに記事を載せられるほどまだ理解していないので、すぐに復習するようにします。\\nL8-Q1: NaN\\nL8-Q2: NaN\\nL8-Q3: NaN\\nL8-Q4: NaN\\nL8-Q5: NaN\\nL9-Q1: NaN\\nL9-Q2: NaN\\nL9-Q3: NaN\\nL9-Q4: NaN\\nL9-Q5: NaN\\nL10-Q1: NaN\\nL10-Q2: NaN\\nL10-Q3: NaN\\nL10-Q4: NaN\\nL10-Q5: NaN\\nL11-Q1: NaN\\nL11-Q2: NaN\\nL11-Q3: NaN\\nL11-Q4: NaN\\nL11-Q5: NaN\\nL12-Q1: NaN\\nL12-Q2: NaN\\nL12-Q3: NaN\\nL12-Q4: NaN\\nL12-Q5: NaN\\nL13-Q1: NaN\\nL13-Q2: NaN\\nL13-Q3: NaN\\nL13-Q4: NaN\\nL13-Q5: NaN\\nL14-Q1: NaN\\nL14-Q2: NaN\\nL14-Q3: NaN\\nL14-Q4: NaN\\nL14-Q5: NaN\\nL15-Q1: NaN\\nL15-Q2: NaN\\nL15-Q3: NaN\\nL15-Q4: NaN\\nL15-Q5: NaN', 'target': 'この学生の成績は、Fです。理由は、講義の後半においてアンケートが未回答であり、学習の継続や理解の確認が行われていないためです。前半の講義では理解を示す回答も見られましたが、後半の講義においては参加や理解の確認がされていないことが成績に影響しています。'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "target_dataset = torch.load(\n",
    "    DATA_PATH / \"GradeExplanationDataset_Qs5_trimmed.pt\", weights_only=False\n",
    ")\n",
    "print(f\"target_dataset keys: {list(target_dataset[0].keys())}\")\n",
    "print(f\"Sample: {target_dataset[0]}\")\n",
    "\n",
    "\n",
    "# target_dataset内のuseridをキーにして，targetをdataに追加する\n",
    "def add_target_to_data(\n",
    "    data: GradeExplanationDataset, target_dataset\n",
    ") -> GradeExplanationDataset:\n",
    "    # Build a mapping from userid to target\n",
    "    userid_to_target = {item[\"userid\"]: item[\"target\"] for item in target_dataset}\n",
    "    for i in range(len(data)):\n",
    "        user_id = data[i][\"userid\"]\n",
    "        if user_id in userid_to_target:\n",
    "            data[i][\"target\"] = userid_to_target[user_id]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82dd6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_target_to_data(data, target_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aa7fa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-Q1: 情報イントロダクション、情報の大まかな仕組み、情報の歴史\n",
      "L1-Q2: 情報は0と1の組み合わせで伝えられていること、モールス信号は作られてから使われるまで時間が空いたこと\n",
      "L1-Q3: 特にないです\n",
      "L1-Q4: NaN\n",
      "L1-Q5: フランスの腕木通信は知らなかったのでおもしろいと思いました。\n",
      "L2-Q1: 情報源とその符号化、望ましい符号\n",
      "L2-Q2: 符号は一意に、素早く戻せるもの、短いものが良い。 語頭符号は一意に、瞬時に戻せる。 平均符号語長がエントロピーを下回ることはない。\n",
      "L2-Q3: 最適符号の定義\n",
      "L2-Q4: 平均符号語長がエントロピーとエントロピーに1を足した値で挟めることは結構すごいことだから、その時の符号を最適符号という、という認識で大丈夫でしょうか。\n",
      "L2-Q5: 前回と比べて、一気にハードになったなと感じました。新しい語句がたくさんでてきて混乱しそうです。\n",
      "L3-Q1: 情報量、曖昧さの減少、情報の期待値、相互情報量\n",
      "L3-Q2: 情報量=曖昧さの減少、起きにくい現象の情報を知った時に得られる情報量は大きい、情報量の期待値はエントロピーに等しい\n",
      "L3-Q3: 曖昧さ=log の証明\n",
      "L3-Q4: 特にないです\n",
      "L3-Q5: エントロピーがまだよくわかっていないので、しっかり復習したいです\n",
      "L4-Q1: ハミング距離、誤り検出と誤り訂正、繰り返し符号、通信路容量\n",
      "L4-Q2: 誤り訂正と誤り検出ができる場合について、ハミング距離の求め方、\n",
      "L4-Q3: 通信路符号化定理、検査ビット\n",
      "L4-Q4: NaN\n",
      "L4-Q5: エントロピーがここでもでできて、重要な存在なのだなと感じました。通信路符号化定理のところと、最後の検査ビットがでてきたところがいまいちよく分からなかったので、ちゃんと復習したいです。\n",
      "L5-Q1: コンピューターサイエンスとは、計算、アルゴリズム\n",
      "L5-Q2: アルゴリズムの定義について\n",
      "L5-Q3: 根付き木がまだよく分からなかった。\n",
      "L5-Q4: NaN\n",
      "L5-Q5: また新しい語句が増えたので、しっかり定着させたいと思いました。コインのアルゴリズムのところが面白かったです。\n",
      "L6-Q1: バブルソート、選択ソート、2進木ソート、ヒープソート\n",
      "L6-Q2: それぞれのソートのやり方\n",
      "L6-Q3: ヒープソートの比較回数にlogが出てくるのがいまいちよくわからないです\n",
      "L6-Q4: NaN\n",
      "L6-Q5: ソートがパズルみたいで面白かったです。特に私は2進木ソートが好きです。\n",
      "L7-Q1: マージソート、二分探索\n",
      "L7-Q2: マージソートのやり方、二分探索のアルゴリズム\n",
      "L7-Q3: キーワードの二分探索がちょっと微妙です\n",
      "L7-Q4: NaN\n",
      "L7-Q5: 線形探索と比べて、二分探索の計算量の少なさに驚きました。\n",
      "L8-Q1: データとは、データの種類、予測、発見、グルーピング\n",
      "L8-Q2: データ分析は身近であること、データを用いた予測、発見、グルーピングのやり方\n",
      "L8-Q3: 特にないです\n",
      "L8-Q4: 特にないです\n",
      "L8-Q5: データ分析はもっと専門的な知識を必要とすると思っていたので、こんなにも身近であることに驚きました。\n",
      "L9-Q1: 人工知能とは、人工知能を用いたビジネス、機械学習、今の人工知能にできないこと\n",
      "L9-Q2: 人工知能は思っている以上に万能ではないこと、人工知能を利用したビジネスの詳細\n",
      "L9-Q3: オープン戦略のあたりがまだ曖昧です\n",
      "L9-Q4: NaN\n",
      "L9-Q5: 人間の脳がいかに優れているかを実感しました。また、顧客監視のような人工知能を使ったビジネスの中にも知らないものがあったので、新しい知識を身に着けることができてよかったです。\n",
      "L10-Q1: 非構造データ(言語、画像、音声)、パターン認識とその応用\n",
      "L10-Q2: 非構造データとは何か、画像はベクトルで表せること、パターン認識とは何か、パターン認識の応用\n",
      "L10-Q3: とくにないです\n",
      "L10-Q4: NaN\n",
      "L10-Q5: 今、線形代数を履修しているので、ベクトル=画像で気を安らげたいと思います。また、深層ニューラルネットワークによるパターン認識が面白いと思いました。\n",
      "L11-Q1: データ収集、全数調査、標本調査、個人情報、オープンデータ、著作権\n",
      "L11-Q2: データ収集の主なやりかた、全数調査と標本調査のメリット・デメリット、個人情報の扱い方\n",
      "L11-Q3: オープンデータのところがまだ少し微妙です。定義はなんとなく理解できましたが、目的の一つである「透明性、信頼性の向上」がまだよく分からないです。\n",
      "L11-Q4: NaN\n",
      "L11-Q5: 個人情報の部分はサイバーセキュリティでやったところと重なっていたのですぐに理解ができました。また、メディアの街頭インタビューのような標本選択バイアスに惑わされないように気をつけようと思いました。\n",
      "L12-Q1: ベクトル、距離、類似度、それらの種類や応用\n",
      "L12-Q2: ベクトルとは何か、ベクトルを用いたデータ分析のやり方、距離の種類、距離や類似度の応用\n",
      "L12-Q3: max距離の使い方とコサイン類似度が微妙です\n",
      "L12-Q4: NaN\n",
      "L12-Q5: 距離と聞くと長さを表す単位(kmやm)が思いつくが、データ解析においても距離を使うのが新鮮で面白かった。\n",
      "L13-Q1: データの可視化、そのいろいろなやり方\n",
      "L13-Q2: 棒グラフや折れ線グラフなど、データの可視化の手法について、データの可視化の利点\n",
      "L13-Q3: 多次元データの可視化\n",
      "L13-Q4: NaN\n",
      "L13-Q5: パイチャートやヒートマップなど、初めて知ったデータの表し方があったので、面白かったです。データの可視化をする際には、どのやり方でするのがよいか、だけでなく、軸の数字や点の配置など、考えなければならないことがたくさんあるんだなと感じました。\n",
      "L14-Q1: 相関、分散、相関係数、統計的検定、画像処理、フィルタ処理、エッジ抽出\n",
      "L14-Q2: 相関係数の求め方、相関や分散や統計的検定の特徴\n",
      "L14-Q3: 微分フィルタ、ソーベルフィルタ\n",
      "L14-Q4: NaN\n",
      "L14-Q5: 高校の数学でやったところが多かったので、懐かしい気分になりました。フィルタ処理のところが難しかったです。\n",
      "L15-Q1: 画像処理の補足、期末テスト\n",
      "L15-Q2: ラプラシアンフィルタについて\n",
      "L15-Q3: NaN\n",
      "L15-Q4: NaN\n",
      "L15-Q5: 期末テストは結構時間がギリギリでした。説明をする記述問題が自信ないです。\n",
      "この学生の成績は、Aです。理由は、質問1と質問2において、講義内容を具体的かつ詳細に説明しており、特に情報の基本概念やアルゴリズム、データ分析手法について深い理解を示しているためです。また、質問3での不明点を具体的に挙げ、質問4で積極的に質問をする姿勢が見られ、学習意欲が高いことが伺えます。質問5では、講義内容に対する興味や新しい知識の習得に対する前向きな姿勢が示されており、全体的に優れた学習態度が評価されます。\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "print(data.__getitem__(idx)[\"input_text\"])\n",
    "print(data.__getitem__(idx)[\"target\"])\n",
    "print(data.__getitem__(idx)[\"grades\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f379242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 15:35:44,820 : src.util : INFO : 58 : Test_message\n",
      "2025-06-18 15:35:44,821 : src.util : INFO : 604 : Questions: [1, 2, 3, 4, 5], Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "\n",
      "2025-06-18 15:35:44,821 : src.util : INFO : 619 : preamble set:\n",
      "================\n",
      "あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\n",
      "さらに、その成績を決定した根拠を簡潔に説明してください。\n",
      "成績と根拠は出力例のような形式で出力してください。\n",
      "入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は、\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "です。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\n",
      "出力には、必ず A、B、C、D、F のいずれかを含めてください。\n",
      "出力例:\n",
      "この学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\n",
      "アンケート内容：\n",
      "================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from logging import INFO, DEBUG\n",
    "from src.util import set_logger\n",
    "\n",
    "logger = set_logger(level=DEBUG)\n",
    "\n",
    "# collatorの動作確認\n",
    "data_collator = GradeExplanationCollator(\n",
    "    tokenizer,\n",
    "    max_tokens=4096,\n",
    "    include_target=True,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2505da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 15:35:44,831 : src.util : DEBUG : 654 : prompt sample:\n",
      "[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に A、B、C、D、F のいずれかに分類してください。\n",
      "さらに、その成績を決定した根拠を簡潔に説明してください。\n",
      "成績と根拠は出力例のような形式で出力してください。\n",
      "入力文のL は講義回、Q は質問番号を示します（例: L1-Q1）。\n",
      "アンケートの質問文は、\n",
      "Q1:今日の内容を自分なりの言葉で説明してみてください\n",
      "Q2:今日の内容で、分かったこと・できたことを書いてください\n",
      "Q3:今日の内容で、分からなかったこと・できなかったことを書いてください\n",
      "Q4:質問があれば書いてください\n",
      "Q5:今日の授業の感想や反省を書いてください\n",
      "です。回答が NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\n",
      "出力には、必ず A、B、C、D、F のいずれかを含めてください。\n",
      "出力例:\n",
      "この学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\n",
      "アンケート内容：\n",
      "\n",
      "L1-Q1: 情報とは0\n",
      "2025-06-18 15:35:44,832 : src.util : DEBUG : 655 : target sample: この学生の成績は、Cです。理由は、各講義において基本的な理解は示しているものの、特に数学的な内容や詳\n",
      "2025-06-18 15:35:44,843 : src.util : DEBUG : 667 : Tokenization Done\n",
      "/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py:692: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_ids[i, -len(ids) :] = torch.tensor(ids)\n",
      "/home/masa1357/Dockerdata/gitfile/LLaVA-FT-datikz_Taiga/notebooks/../src/gradeexplanation_data.py:693: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_lbl[i, -len(lbl) :] = torch.tensor(lbl)\n",
      "2025-06-18 15:35:44,847 : src.util : DEBUG : 704 : Collating Done\n",
      "2025-06-18 15:35:44,847 : src.util : DEBUG : 706 : Collate: 2 samples, max_tokens=4096\n",
      "2025-06-18 15:35:44,849 : src.util : INFO : 10 : Batch keys: dict_keys(['input_ids', 'attention_mask', 'labels', 'target_ids'])\n",
      "2025-06-18 15:35:44,850 : src.util : INFO : 14 : Batch key: input_ids, value shape: torch.Size([2, 3886])\n",
      "2025-06-18 15:35:44,850 : src.util : INFO : 14 : Batch key: attention_mask, value shape: torch.Size([2, 3886])\n",
      "2025-06-18 15:35:44,851 : src.util : INFO : 14 : Batch key: labels, value shape: torch.Size([2, 3886])\n",
      "2025-06-18 15:35:44,852 : src.util : INFO : 14 : Batch key: target_ids, value shape: torch.Size([2, 127])\n",
      "2025-06-18 15:35:44,860 : src.util : DEBUG : 21 : batch:\n",
      "{'input_ids': tensor([[128256, 128256, 128256,  ...,  38641,   1811, 128009],\n",
      "        [    58,  65562,     60,  ...,  61689,   1811, 128009]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[  -100,   -100,   -100,  ...,  38641,   1811, 128009],\n",
      "        [  -100,   -100,   -100,  ...,  61689,   1811, 128009]]), 'target_ids': tensor([[ 51330, 106718,  16144,  13153, 116486,  15682,   5486,     34,  38641,\n",
      "           1811, 114667,  15682,   5486, 102208, 114341, 104577, 121960, 108729,\n",
      "         109904, 113954,  15682,  20379, 103792, 102944,  16144,   5486,  66378,\n",
      "          20230, 118687, 109904,  44915,  71289, 116718,  26854, 105494, 113245,\n",
      "         113954,  29295,  16937, 114392, 103195, 105908,  43240,  47884,   5486,\n",
      "          53900,  23538, 106968,  57933,  71634, 121960,  32977,  82973,  55487,\n",
      "          17620,  29295,  30297,  17129,  47884, 103082, 101860,   5486, 109606,\n",
      "          30512,  50338,  47884,  82973,  29295, 102780,  31431, 104435, 103846,\n",
      "          38641,   1811, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256, 128256,\n",
      "         128256],\n",
      "        [ 51330, 106718,  16144,  13153, 116486,  15682,   5486,     32,  38641,\n",
      "           1811, 114667,  15682,   5486, 105284,  99397,     16, 121960,   5486,\n",
      "         114341, 104577,  44915,  30512, 118789,   9554,  32149,  59739, 116718,\n",
      "          20230, 122984, 126020,   5486,  53900, 105284,  99397,     17, 121960,\n",
      "          32977, 113954,  56051,  44915,  30512,   9554, 105184,  20230,  43032,\n",
      "         103854, 100934, 103846,  38641,   1811, 122270,   5486, 105284,  99397,\n",
      "             18,  77181, 115364, 113954,  29295,  16937, 114392,  26854,  28542,\n",
      "          30512, 104736, 109375,  15024,   5486, 109095, 108710,  16144,  37689,\n",
      "         111654,  30512,  20379, 103792, 100909,  55031,   5486,  48864, 108710,\n",
      "         113115,  54926, 108882, 110993, 109904, 110783, 110095,  29295,  17885,\n",
      "            118,  58942,  33541,   1811,  37087,  33014,  30512,  33035,  39926,\n",
      "           5486, 114341, 104577,  44915,  16144, 113954,  27479,  29295,  45736,\n",
      "          47884,   5486, 102099,  48864, 108710, 111363,  37689, 111654,  32977,\n",
      "         126574, 105908,  13153, 116486,  20230,  95543, 106482, 116216,  61689,\n",
      "           1811]])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data,\n",
    "    batch_size=2,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    ")\n",
    "batch = next(iter(data_loader))\n",
    "logger.info(\n",
    "    f\"Batch keys: {batch.keys()}\"\n",
    ")  # -> Batch keys: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
    "for k, v in batch.items():\n",
    "    logger.info(\n",
    "        f\"Batch key: {k}, value shape: {v.shape if isinstance(v, torch.Tensor) else type(v)}\"\n",
    "    )\n",
    "# batch内のinput_idsをでコードしてプロンプトを確認\n",
    "input_text = tokenizer.batch_decode(batch[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "logger.debug(f\"batch:\\n{batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01339275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Input prompt: \\n'\n",
      " \"['[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に \"\n",
      " 'A、B、C、D、F '\n",
      " 'のいずれかに分類してください。\\\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\\\n成績と根拠は出力例のような形式で出力してください。\\\\n入力文のL '\n",
      " 'は講義回、Q は質問番号を示します（例: '\n",
      " 'L1-Q1）。\\\\nアンケートの質問文は、\\\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\\\nQ4:質問があれば書いてください\\\\nQ5:今日の授業の感想や反省を書いてください\\\\nです。回答が '\n",
      " 'NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\\\n出力には、必ず A、B、C、D、F '\n",
      " 'のいずれかを含めてください。\\\\n出力例:\\\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\\\nアンケート内容：\\\\n\\\\nL1-Q1: '\n",
      " '情報とは01で表現され、日々の生活に反映されてる。 過去、人々は情報伝達の技術を発達させていった。\\\\nL1-Q2: '\n",
      " '現代の生活で情報の通信がどのように行われているか知ることができた。 情報伝達の歴史について知ることができた。\\\\nL1-Q3: '\n",
      " '初回の授業で導入部分であったため、疑問に思うことはなかった。\\\\nL1-Q4: なし\\\\nL1-Q5: '\n",
      " '現代は情報が非常に大切なのに、高校までの情報の授業は詳しい内容をしてこなっかったので大学で学べることに感謝している。 '\n",
      " '腕木通信など、自分の知らない情報伝達の方法などを知ることができ良かった。\\\\nL2-Q1: 情報源符号化は一意に、素早く元に戻せることが必要 '\n",
      " '一意複号とはそれ一通りしかないこと 瞬時復号とはその復号語が先読みせずに読み終えることができること '\n",
      " 'エントロピーによって表される最短の平均符号語長を最適符号という\\\\nL2-Q2: '\n",
      " '符号化したものを復号するタメに、なるべく短い長さで正確に符号化する必要があり、最も良いものが最適符号と呼ばれる\\\\nL2-Q3: '\n",
      " '確率や平均符号語長のところ\\\\nL2-Q4: NaN\\\\nL2-Q5: '\n",
      " '数学的なところは理解するのが難しかったけど、それによって何が言いたいのかはわかった\\\\nL3-Q1: '\n",
      " '情報源の曖昧さは、情報源のエントロピーと一致していて、その減少量を情報量という。滅多に起きない事象の生起を知ることで得られる情報量は大きい。 '\n",
      " '情報量の期待値、つまりエントロピーは確率二分の一の時最大値1をとる。\\\\nL3-Q2: '\n",
      " '情報量の大きさや期待値を対数を取って計算できることがわかった。\\\\nL3-Q3: 相互情報量について理解ができなかった\\\\nL3-Q4: '\n",
      " 'NaN\\\\nL3-Q5: 数学的になり、理解するのが大変になってきた。\\\\nL4-Q1: '\n",
      " '情報を送る際、必ずノイズが発生する。そのノイズによる影響を小さくするために冗長化や繰り返し符号などを活用する。ただ、ブロック誤り率を小さくしようとすると情報量が増加し、効率が落ちてしまう。\\\\nL4-Q2: '\n",
      " '高々t個の誤り訂正については、蟻地獄の考えですぐに理解できた。ノイズの影響を小さくするためには情報量を増やす必要があることがわかった。\\\\nL4-Q3: '\n",
      " '通信路符号化定理についてはよくわからなかった。\\\\nL4-Q4: NaN\\\\nL4-Q5: 図の説明がすごくわかりやすかった。\\\\nL5-Q1: '\n",
      " 'コンピュータで関数の計算方法を示す手続きをアルゴリズムといい、単純な計算の組み合わ背である。また、プログラムとはそれをコンピューターがわかる言語記述したものである。計算を効率的に行うためにはできるだけ基本演算の回数を少なくして、計算ステップ数を少なくすることが大切である。\\\\nL5-Q2: '\n",
      " '普段何気なく聞くアルゴリズムやプログラムとはどういうものかわかった。また、ただ計算すればいいわけではなく、計算ステップ数を少なくしなければならないことがわかった。\\\\nL5-Q3: '\n",
      " '大まかにはわかったが、3進木の理解が難しかった\\\\nL5-Q4: NaN\\\\nL5-Q5: コインの例があったため理解しやすかった\\\\nL6-Q1: '\n",
      " '数の大小の並び替え、ソートについて4種類の方法を学んだ。入力によって計算量は変化し、最悪な長さの場合のことを考えるようにする。\\\\nL6-Q2: '\n",
      " '2進木ソートの数列の並び方で計算時間が変化する欠点を補うためにヒープソートが使われており、手順が2段階に増える。ただ、入力整数の数が小さいときはヒープソートよりも二進木ソートの方が最悪の比較回数は少ない。バブルソート、選択ソート、2進木ソートについては時間計算量のオーダー記法は同じである。\\\\nL6-Q3: '\n",
      " '2進木ソートの考えはなんとなくわかったが、どうやってヒープソートで2進木ソートの欠点が補われたのかがよく分からなかった。\\\\nL6-Q4: '\n",
      " 'NaN\\\\nL6-Q5: ヒープソートが複雑で理解するのが難しかった。\\\\nL7-Q1: '\n",
      " 'マージソートとは2進木を使用せず、分割できるところまで分割し続け、その後2つの数列をマージしていくことで元の数列がソートされる。端から順に調べる線形探索とは異なり、2分探索は半分のところから調べるため圧倒的に早く調べることができる。それを応用してキーワードの検索が行われる。\\\\nL7-Q2: '\n",
      " '2進木やヒープソートよりマージソートの方がシンプルで速くソートできる。普段使っているキーワード検索は2分探索を活用している。\\\\nL7-Q3: '\n",
      " '接尾辞配列がなぜシンプルで優れているのかがよく分からなかった。\\\\nL7-Q4: NaN\\\\nL7-Q5: '\n",
      " '前回のソート方法に比べ、今回のマージソートはわかりやすかった。2分探索はわかったが、接尾辞の部分は理解が難しかった。\\\\nL8-Q1: '\n",
      " 'データは一般的に4種類に分類でき、データによって使える手法が異なる。私たちは日頃からデータ分析をして物事の予測を立てている。データの相関やグルーピングによりデータを扱うことができるが、その方法によって結果が変わるため技量が試される。\\\\nL8-Q2: '\n",
      " '現代社会にをいてどの分野でもデータを扱うことは重要である。データ分析をすることで何かしらの結果を得ることができるが、その結果は方法によって変わるため注意が必要。\\\\nL8-Q3: '\n",
      " 'データ分析の詳しいところについてはできないと思うが概ねわかった。\\\\nL8-Q4: NaN\\\\nL8-Q5: '\n",
      " 'データ分析は自分自身にとっても重要なことであり、それを学んでそして活用したいと思った\\\\nL9-Q1: '\n",
      " '自分たちの普段の生活の中ではありとあらゆる場面でAIが使われており、AIを活用することで便利な生活を送ることができている。しかしAIとは万能なものではなく、基本的には一つの物事に特化しており、また膨大なデータによる機械学習が必要であり、ノイズや特定の範囲外のことが起きると使い物にならないなど様々な弱点が存在する。\\\\nL9-Q2: '\n",
      " '現実のAIとはSF世界のものとは違って万能なものではないが、情報処理などAIの得意なことをやらせる分には強力な味方となり今の私たちの生活には必要不可欠なものとなっている。\\\\nL9-Q3: '\n",
      " '深層ニュートラルネットワークについて、ものすごい数の演算を行なっていることくらいしか分からなかった。\\\\nL9-Q4: NaN\\\\nL9-Q5: '\n",
      " '近年様々なメディアに取り上げられることの多くなったAIとはどういったものなのかを学び、決して万能なものではないがとても便利なものであることがわかった。\\\\nL10-Q1: '\n",
      " 'NaN\\\\nL10-Q2: NaN\\\\nL10-Q3: NaN\\\\nL10-Q4: NaN\\\\nL10-Q5: NaN\\\\nL11-Q1: '\n",
      " 'データの収集で理想的なのは全数調査だが、母数が大きいと標本調査を行う。その標本のバイアスが入らないようにランダム性を重視している。 '\n",
      " '個人情報とはその個人を特定できるようになる情報のことであり、不当な差別や偏見が生じる恐れのあるものは要配慮個人情報と呼ばれる。 '\n",
      " '市民や企業が使いやすい公共データをオープンデータという。\\\\nL11-Q2: '\n",
      " '国民調査とは日本国民全員を対象とした、理想的な調査である全数調査だということがわかった。 '\n",
      " '個人情報は組み合わせることで特定が可能となる情報も含まれていることを知った。\\\\nL11-Q3: '\n",
      " 'オープンデータについて詳しくはよくわからなかった\\\\nL11-Q4: NaN\\\\nL11-Q5: '\n",
      " '標本選択バイアスを考慮してデータを見ないと悪意ある人に騙されるかもしれないと考えると怖くなった。個人情報、オープンデータといったものはどういったものか知れてよかった。\\\\nL12-Q1: '\n",
      " 'さまざまな数値などのデータはベクトルで表現でき、線形代数の考えを使うことができる。データ分析において距離と類似度は基本的な道具である。 '\n",
      " '距離にはユークリッド距離の他にマンハッタン距離やmax距離など様々な距離の測り方がある。 '\n",
      " '距離や類似度を利用して画像認識やクラスタリングができる。\\\\nL12-Q2: '\n",
      " 'データの分析において距離が変われば結果も変わるためどれを使うかという判断が重要になると知った。 '\n",
      " '距離といえばユークリッド距離だけでなく、様々な種類の距離があることがわかった。\\\\nL12-Q3: '\n",
      " '編集距離、コサイン類似度はどういう距離なのかよくわからなかった\\\\nL12-Q4: NaN\\\\nL12-Q5: '\n",
      " '距離ということで数学ぽさが出てきたが、これまでの数学とは違いその目的がはっきりしているのでとっつきやすかった。\\\\nL13-Q1: '\n",
      " '膨大なデータでも図を使って可視化すると把握できるようになる。さまざまな種類の図やグラフがあるがそれぞれに特徴や注意点などが存在するため適切なものを選んで使う必要がある。多次元のデータでも散布図を使い、要素数を減らしたりすることで可視化することができる。また、要素数を減らすためには行列など数学の知識が必要となる。\\\\nL13-Q2: '\n",
      " '可視化によってデータを直感んてきに理解できるようになり、次に行う分析の方針決定につながる。可視化の手法はその目的に合わせて使う図やグラフが異なり、適切なものを選ぶ必要がある。また、多次元のデータを扱う際には数学の知識を利用して要素数を減らしてあげる必要がある。\\\\nL13-Q3: '\n",
      " '多次元データのところの複数の要素を直線や平面で表現する、というところがさっぱりわからなかった。\\\\nL13-Q4: NaN\\\\nL13-Q5: '\n",
      " '高校の授業である程度図やグラフについて学んだが、それぞれどんな目的で利用するのかは知らなかったのでためになった。複数の要素を含むデータも工夫することで可視化できるようになるというのが難しかったが同時に感動もした。\\\\nL14-Q1: '\n",
      " '2つの量の関係性を説明する方法が相関でデータの広がり具合のことを分散という。相関係数を使うことで相関を数値で表現できるようになる。統計的検定とは差を評価する枠組みで、差がないことを仮説を立て過去のデータから確率を計算して基準と比較して評価する。画像解析にはフィルタ処理というものがあり平滑化やエッジ抽出などができる。フィルタには平均化フィルタの度様々な種類がある。\\\\nL14-Q2: '\n",
      " '統計的検定という初めて聞く方法ではデータに差があることがわかり、2集団の差についてまで検定できるようになる。また、画像解析では画像の加工をする際に行われていることについてフィルタ処理というものを行なっていることがわかった。\\\\nL14-Q3: '\n",
      " 'フィルタ処理の仕組みについて、例を見てもよくわからなかった\\\\nL14-Q4: NaN\\\\nL14-Q5: '\n",
      " '統計的検定というデータの評価方法について初めて知ることができた。普段画像を見やすくしたりする作業で使っているのがフィルタ処理と呼ばれる作業でその仕組みまで知ることができた。短にこういった方法が使われていることを知れてためになった。\\\\nL15-Q1: '\n",
      " '期末テストを行った\\\\nL15-Q2: AIに関する問題などはできた\\\\nL15-Q3: '\n",
      " '記述問題を書く時間と計算問題を解く時間がなかった。ほぼノータイムで答えを記入しないと間に合わなかったが、考える時間や思い出す時間を作ってしまったため何問か問題すら読むことができなかった。\\\\nL15-Q4: '\n",
      " 'NaN\\\\nL15-Q5: '\n",
      " \"即答できるほどに記憶を定着させられなかったので、今後おそらく他の教科にはなると思うがまだまだ頑張らないといけないと感じた。\\\\n[/INST]\\\\nこの学生の成績は、Cです。理由は、各講義において基本的な理解は示しているものの、特に数学的な内容や詳細な部分での理解が不十分であることが多く、また期末テストにおいても時間配分がうまくできず、問題を解く時間が足りなかったためです。', \"\n",
      " \"'[INST] あなたは大学の教授であり、学生の成績を決定する役割を担っています。以下に示す学生の講義後アンケートを読み、成績を高い順に \"\n",
      " 'A、B、C、D、F '\n",
      " 'のいずれかに分類してください。\\\\nさらに、その成績を決定した根拠を簡潔に説明してください。\\\\n成績と根拠は出力例のような形式で出力してください。\\\\n入力文のL '\n",
      " 'は講義回、Q は質問番号を示します（例: '\n",
      " 'L1-Q1）。\\\\nアンケートの質問文は、\\\\nQ1:今日の内容を自分なりの言葉で説明してみてください\\\\nQ2:今日の内容で、分かったこと・できたことを書いてください\\\\nQ3:今日の内容で、分からなかったこと・できなかったことを書いてください\\\\nQ4:質問があれば書いてください\\\\nQ5:今日の授業の感想や反省を書いてください\\\\nです。回答が '\n",
      " 'NaN の場合は未回答であり、回答文字数が一定以上ならば切り捨てています。\\\\n出力には、必ず A、B、C、D、F '\n",
      " 'のいずれかを含めてください。\\\\n出力例:\\\\nこの学生の成績は、Aです。理由は、質問１において、講義内容を数式を用いて詳細に説明しており、講義内容の理解度が高いためです。\\\\nアンケート内容：\\\\n\\\\nL1-Q1: '\n",
      " '昔から様々な方法で情報は伝達されてきた。 それは近代になって複雑に暗号化された。\\\\nL1-Q2: '\n",
      " '携帯のない昔の人は、様々に工夫して情報を伝達してきたということ。\\\\nL1-Q3: なぜ1バイトが8ビットなのか。\\\\nL1-Q4: '\n",
      " 'NaN\\\\nL1-Q5: 情報という分野に興味を持った。 高校で学習した内容より深く知りたいと思った。\\\\nL2-Q1: '\n",
      " '情報は様々な形態に変換されて送られるが、ただ闇雲に変換すればいいというものではなく、気をつけなければいけないことが多々ある。\\\\nL2-Q2: '\n",
      " '変換の仕方によっては違う情報が同じ内容として送られてしまうので復元できなくなってしまうことがわかった。\\\\nL2-Q3: '\n",
      " '前の内容だが、小テストでMBがわからなかったので、復習しておきたい。\\\\nL2-Q4: NaN\\\\nL2-Q5: '\n",
      " 'エントロピーを理解するのに時間がかかった。難しくなっても授業に付いていきたい。\\\\nL3-Q1: '\n",
      " '得られる情報の量は「曖昧さの減少」で表され、-log2(M)となる。また、期待値はエントロピーに一致する。\\\\nL3-Q2: '\n",
      " '起こる確率が大きい事象は1と近似され、平均に含まれないことがわかった。\\\\nL3-Q3: '\n",
      " 'どこまで近似できてどこから近似できないのか調べてみようと思った。\\\\nL3-Q4: NaN\\\\nL3-Q5: '\n",
      " '難しかったが、前回の内容と合わせて理解出来た。\\\\nL4-Q1: '\n",
      " '情報を伝達する段階で誤りが起こるとき、通信路の符号化によって自動的に誤り検出、誤り訂正をすることができる。\\\\nL4-Q2: '\n",
      " 'ビットの量によって誤り検出、訂正ができないというのが最初はよくわからなったが、名前の例を聞いてよく分かった。間違いすぎているとコンピューターでも訂正ができないので、情報の伝達は難しいと思った。\\\\nL4-Q3: '\n",
      " '立式がなぜそうなるのか、よくわからない式がいくつかあったので自分で調べてみようと思った。\\\\nL4-Q4: NaN\\\\nL4-Q5: '\n",
      " '先週よりわからないことが少しあったが、来週から内容が変わっていくのでしっかり復習しておきたい。\\\\nL5-Q1: '\n",
      " '数学的に厳密に定義された「問題」の関数を解く方法をコンピュータに示したものをアルゴリズムといい、根付き木などを使って簡略に図化できる。\\\\nL5-Q2: '\n",
      " 'アルゴリズムの定義として、関数の計算方法を示すものと単純な計算方法の組み合わせ方の2つがあり、授業で結局は同じ意味だと分かったので面白いと思った。偽コインの発見問題は何度か遊びでしたことがあったが、このように根付き木で考えたのは初めてだったのでとても分かりやすいと思った。\\\\nL5-Q3: '\n",
      " '小テストで偽コインの発見問題を間違えてしまったので、復習しておきたい。\\\\nL5-Q4: NaN\\\\nL5-Q5: '\n",
      " 'これまでの内容と変わったが、とても興味深い内容なので次回の授業も楽しみです。\\\\nL6-Q1: '\n",
      " '複数個のアイテムを「ある順序」に従って並び替えることをソートという。ソートにはさまざまな種類があり、それぞれの比較回数、オーダー表記などの点を考慮しながら用途に応じて使い分けることが必要である。\\\\nL6-Q2: '\n",
      " 'ただ数字を並び替えるという作業に様々なやり方があるということに驚いたが、それぞれ違った方法であり、ソートに求めるスピードや安全性に応じてどれを使うのか考えるということが大変だが面白いと思った。\\\\nL6-Q3: '\n",
      " 'ヒープソートについての練習問題2が、一度説明を聞いただけでは完璧に理解できずあやふやなので自分で復習しておこうと思う。\\\\nL6-Q4: '\n",
      " 'NaN\\\\nL6-Q5: '\n",
      " '個人的には一回一回比較するのが面倒なのでマージソートが使いやすいなと思った。調べてみたところ安全性も高く、ヒープソートよりも使いやすいと書いてあったので、一度半分に分けるというのは便利だなと思った。\\\\nL7-Q1: '\n",
      " '分割した数列の比較を再帰的に繰り返すソートをマージソートといい、比較回数は高々nlog(2)nである。また、整列された要素から半分ずつ探索するアルゴリズムを二分探索アルゴリズムといい、時間計算量はO(klogn)である。\\\\nL7-Q2: '\n",
      " 'マージソートも二分探索も半分に分けるというやり方が主体となっていたが、とても簡単でやりやすいと思った。やり方や比較回数の考え方もわかった。\\\\nL7-Q3: '\n",
      " '今回はすべて理解できた。\\\\nL7-Q4: NaN\\\\nL7-Q5: '\n",
      " 'とてもやりやすい二分探索がごく最近まで知られていなかったというのはとても驚いたし、同じようにまだ知られていないやりやすい探索法もあるのだろうと思った。他の探索法についても調べてみたいと思う。\\\\nL8-Q1: '\n",
      " 'データには様々なものがあり、大きく4つに分類される。また、データ分析の基本は3つに分類でき、予測、傾向や関連の発見、グルーピングに分けられる。これらは私たちが普段無意識にしていることである。\\\\nL8-Q2: '\n",
      " 'データ分析といわれると難しそうな印象がしたが、話を聞いてとてもよく分かったし、効率的に毎日を過ごす上で無意識的にしていることだということも分かった。疑似相関の話にはとても納得したが、よく考えないと単なる総監だと勘違いしてしまいそうなので怖いなと思った。\\\\nL8-Q3: '\n",
      " 'グルーピングにおいて、「似ている」ということは個人の主観であるので、数学的に判断できないものはクラスタリングが個人によって違うため、とても難しいなと思った。似ている具合を複数人で決めるときどのようにするべきなのか調べてみようと思う。\\\\nL8-Q4: '\n",
      " 'NaN\\\\nL8-Q5: '\n",
      " '普段の生活に当てはまることが多く、とても興味深い内容だった。次回からの授業に出てくるとあった単語も多かったので復習しておきたい。次回からの授業が楽しみです。\\\\nL9-Q1: '\n",
      " '特定のことしかできないAIを特化型AIといい、現在利用されているのは全てがこれである。これは一般的に「弱いAI」とも呼ばれる。私たちの身の回りにはAIが溢れており、機械学習を使って様々なビジネスにも利用されてきているが、関数であるAIは様々な理由から全く万能ではない。\\\\nL9-Q2: '\n",
      " 'AIというと何でもできるというイメージがあったが、全てのAIは全く万能ではなく一つのことしかできないことが分かった。ただ、深層ニューラルネットワークという考え方を活用させて強いAIを作ることができたら、いろんな分野のことが発展するのだろうと思った。\\\\nL9-Q3: '\n",
      " '「強い」「弱い」という曖昧な表現を使っていることが最初疑問に思ったが、話を聞いているとそこの境界は曖昧なものであるということが分かった。情報科学の分野では曖昧な言葉がたまに出てくるので面白いと思った。\\\\nL9-Q4: '\n",
      " '「人間の活動は近い未来に全てがコンピュータに取って代わられる」とよく聞くが、今回の講義を聞いて本当なのか?と疑問に思った。AIが人間を超えて動ける日が来るのはとても遠いのではないかと思う。\\\\nL9-Q5: '\n",
      " '特化型AIが万能ではない根拠として三つ挙げられていたが、とても分かりやすく、特にフレーム問題に関してはAIの恐ろしさが伝わった。AIは近年の最も重要な題材の一つなので、他のことについても調べてみようと思う。\\\\nL10-Q1: '\n",
      " '表形式ではないデータを非構造化データというが、その処理には言語処理、画像処理、音声処理などがある。また、コンピュータが様々なデータをもとにそれが何であるかを当てる方法をパターン認識というが、なんでもできるわけではない。\\\\nL10-Q2: '\n",
      " 'パターン認識の話は前回の授業で理解していたが、人間が「なんとなく」していることがコンピュータには難しいというのがますますわかった。大量のデータを一度に処理するコンピュータは便利ですごいが、どうしてもできないことはあるのだなと思う。\\\\nL10-Q3: '\n",
      " '「似てる具合」の考え方について、深入りしていくと本当にこんがらがってわからなくなった。人間とコンピュータは違うということがよくわかる。\\\\nL10-Q4: '\n",
      " 'NaN\\\\nL10-Q5: '\n",
      " 'コンピュータができないこともよくわかったが、今コンピュータがしている様々なデータの分析がないと私たちは生きていけない体になっていると思うので、逆にコンピュータが私たちの能力を超える日がもし来ると思うと怖いと思った。\\\\nL11-Q1: '\n",
      " 'データ調査の理想的手法は全数調査だが、それは事実上不可能であるため様々な調査法で行う。また、調査における偏りのことをバイアスといい、なるべく小さくする必要がある。個人情報においては保護と利用のバランスが大切であり、利用に特化したデータとしてオープンデータの活用が推奨されている。\\\\nL11-Q2: '\n",
      " 'メディアの報道についての問題点は何度か聞いたことがあったが、バイアスの話を聞いてとても納得した。オープンデータという言葉は聞いたことがあったが詳しい内容については知らなかったのでとても興味深かったが、ホームページで利用されているとオープンデータということではないということだったので難しいなと思った。\\\\nL11-Q3: '\n",
      " 'バイアスを減らすために様々な標本調査法が考えられていても、それぞれにどうしても問題点が発生してしまうのはとても難しいことだと思った。結局一番良い調査法はどのようなものなのか気になったので調べてみようと思う。\\\\nL11-Q4: '\n",
      " 'NaN\\\\nL11-Q5: '\n",
      " '個人情報については他の授業でも何度か触れたことがあったので理解しやすかった。他者のデータを利用するためには複雑なルールが必要だと分かったので、気を付けないといけないなと思った。\\\\nL12-Q1: '\n",
      " '数値の組であるベクトルは順番に意味があり、様々なものを表現したりデータを分析したりできる。距離と類似度はデータ分析の基本的な道具であり、距離はデータ間の違い、類似度は似ている度を表す。距離には様々なものがあり、場面によって使い分ける。\\\\nL12-Q2: '\n",
      " '中学、高校と距離を学んできて、距離と聞いて自分がイメージしていたものはユークリッド距離であることが分かった。情報の世界では距離は条件を満たすと何でもよく、様々なものがあって用途によって必要な場面が変わることが分かったので面白いなと思った。\\\\nL12-Q3: '\n",
      " 'ユークリッド距離、マンハッタン距離、max距離の等距離面での違いの図が完璧には理解できずあやふやな箇所があるので、よく確認しておこうと思う。\\\\nL12-Q4: '\n",
      " 'cos類似度があるならsin類似度はどうなのか、と思ったが、内積を利用するということだったので恐らくないのだろうと思う。\\\\nL12-Q5: '\n",
      " '距離、類似度がどのようなものなのか、どのように使うのかよく分かった。何週か前からよく出てくる「似ている度」が最初は全然わからなかったが大分わかるようになってきたので、前の授業をもう一度復習しておこうと思う。\\\\nL13-Q1: '\n",
      " 'データの可視化の方法には様々なものがあり、何をどのように表したいかによって使い分ける必要がある。データの差を表したい場合や散らばり具合を表したい場合、割合を表したい場合などいろいろなグラフで表現できるが、それぞれのグラフで注意点があるので注意しながら表すべきである。\\\\nL13-Q2: '\n",
      " '知らなかった表現方法もいくつかあり、表したいデータによってとても細かく分けられることが分かった。\\\\nL13-Q3: '\n",
      " '3次元以上のデータの表し方が完璧には理解できていないので、もう一度スライドを見ようと思う。\\\\nL13-Q4: NaN\\\\nL13-Q5: '\n",
      " '小、中、高とデータの勉強は少しずつしてきたのでわかりやすかったが、難しい箇所もあったので復習しておこうと思う。\\\\nL14-Q1: '\n",
      " '相関は2つの量の関係性であり、データの広がりを表す分散だけでは不十分である際に用いられる。 '\n",
      " '統計的検定は統計的に差を評価する枠組みである。これは、帰無仮説を考えてそれを信じ、起こる確率を計算してから有意水準と比較するという方法である。\\\\nL14-Q2: '\n",
      " '有意水準を低く設定することで得られる情報が大きくなることが分かった。\\\\nL14-Q3: NaN\\\\nL14-Q4: NaN\\\\nL14-Q5: '\n",
      " '相関については高校で勉強していたのでわかりやすかった。 検定の話も面白いと思ったのでもっと詳しく知りたいと思った。\\\\nL15-Q1: '\n",
      " '画像は様々なデータが複雑に入っている。 画像や音声、動作などからデータを認識できるシステムなども開発された。\\\\nL15-Q2: '\n",
      " '画像についてのスライドは理解することができた。\\\\nL15-Q3: NaN\\\\nL15-Q4: NaN\\\\nL15-Q5: '\n",
      " 'テストだったので緊張したが、今まで学習したことを生かしてできたと思う。 '\n",
      " \"半年間の講義ありがとうございました。\\\\n[/INST]\\\\nこの学生の成績は、Aです。理由は、質問1において、講義内容を具体的かつ詳細に説明しており、また質問2においても理解した内容を的確に述べているためです。さらに、質問3では自分の理解が不十分な点を認識し、復習の意欲を示していることから、学習に対する積極的な姿勢が伺えます。全体を通して、講義内容の理解度が高く、自己学習への意欲も高いことが成績に反映されています。']\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(f\"Input prompt: \\n{input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc608ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# targetのトークン数分布を確認\n",
    "def count_target_tokens(data: GradeExplanationDataset) -> Dict[str, int]:\n",
    "    target_token_counts = {}\n",
    "    for item in data:\n",
    "        target = item[\"target\"]\n",
    "        if isinstance(target, str):\n",
    "            tokens = tokenizer.encode(target, add_special_tokens=False)\n",
    "            target_token_counts[item[\"userid\"]] = len(tokens)\n",
    "    return target_token_counts\n",
    "\n",
    "\n",
    "target_token_counts = count_target_tokens(data)\n",
    "# トークン数の分布を表示\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_token_distribution(token_counts: Dict[str, int]) -> None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(list(token_counts.values()), bins=50, color=\"blue\", alpha=0.7)\n",
    "    plt.title(\"Target Token Count Distribution\")\n",
    "    plt.xlabel(\"Number of Tokens\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(axis=\"y\", alpha=0.75)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_token_distribution(target_token_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
